{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1385483</th>\n",
       "      <td>4</td>\n",
       "      <td>2052752838</td>\n",
       "      <td>Sat Jun 06 01:53:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tonyvirtual</td>\n",
       "      <td>How do you like my outfit? Looking good?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657684</th>\n",
       "      <td>0</td>\n",
       "      <td>2241121485</td>\n",
       "      <td>Fri Jun 19 10:33:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rudyx760</td>\n",
       "      <td>Wish i lived in Santa Monica to go to the &amp;quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410415</th>\n",
       "      <td>0</td>\n",
       "      <td>2059872092</td>\n",
       "      <td>Sat Jun 06 17:48:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cfierce</td>\n",
       "      <td>@Hope_Isabel nothinggg, just wokeee up and I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244414</th>\n",
       "      <td>4</td>\n",
       "      <td>1994806104</td>\n",
       "      <td>Mon Jun 01 12:29:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>danbraithwaite</td>\n",
       "      <td>Downloading flash catalyst beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494505</th>\n",
       "      <td>4</td>\n",
       "      <td>2069713004</td>\n",
       "      <td>Sun Jun 07 16:23:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thebeanboy23</td>\n",
       "      <td>@Squibby_ twas good. Freakshow and womanizer h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "1385483       4  2052752838  Sat Jun 06 01:53:22 PDT 2009  NO_QUERY   \n",
       "657684        0  2241121485  Fri Jun 19 10:33:58 PDT 2009  NO_QUERY   \n",
       "410415        0  2059872092  Sat Jun 06 17:48:25 PDT 2009  NO_QUERY   \n",
       "1244414       4  1994806104  Mon Jun 01 12:29:17 PDT 2009  NO_QUERY   \n",
       "1494505       4  2069713004  Sun Jun 07 16:23:21 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \n",
       "1385483     tonyvirtual          How do you like my outfit? Looking good?   \n",
       "657684         rudyx760  Wish i lived in Santa Monica to go to the &quo...  \n",
       "410415          cfierce  @Hope_Isabel nothinggg, just wokeee up and I'm...  \n",
       "1244414  danbraithwaite                   Downloading flash catalyst beta   \n",
       "1494505    thebeanboy23  @Squibby_ twas good. Freakshow and womanizer h...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_COLUMNS = [\"target\",\"ids\",\"date\",\"flag\",\"user\",\"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "df = pd.read_csv(\"Datasets/training.1600000.processed.noemoticon.csv\",encoding=DATASET_ENCODING, names = DATASET_COLUMNS)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800000</td>\n",
       "      <td>593879</td>\n",
       "      <td>1</td>\n",
       "      <td>415671</td>\n",
       "      <td>790185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800000</td>\n",
       "      <td>286578</td>\n",
       "      <td>1</td>\n",
       "      <td>376569</td>\n",
       "      <td>793506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ids    date  flag    user    text\n",
       "target                                      \n",
       "0       800000  593879     1  415671  790185\n",
       "4       800000  286578     1  376569  793506"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"target\").nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df[[\"text\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...       0\n",
       "1  is upset that he can't update his Facebook by ...       0\n",
       "2  @Kenichan I dived many times for the ball. Man...       0\n",
       "3    my whole body feels itchy and like its on fire        0\n",
       "4  @nationwideclass no, it's not behaving at all....       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"target\"]= train[\"target\"].replace(4,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599995    1\n",
       "1599996    1\n",
       "1599997    1\n",
       "1599998    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"][-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = train[train[\"target\"]==1] \n",
    "data_neg = train[train[\"target\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data_pos.iloc[:int(20000)]\n",
    "data_neg = data_neg.iloc[:int(20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([data_pos,data_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19995    not much time off this weekend, work trip to m...\n",
       "19996                            one more day of holidays \n",
       "19997    feeling so down right now .. i hate you damn h...\n",
       "19998    geez,i hv to read the whole book of personalit...\n",
       "19999    i threw my sign at donnie and he bent over to ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"text\"] = combined[\"text\"].str.lower()\n",
    "combined[\"text\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is any null \n",
    "# combined[\"selected_text\"].fillna(\"No context\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "\n",
    "def clean_data(data):\n",
    "    \n",
    "    #Removing URLs \n",
    "    url_pattern = re.compile(r\"https?://\\S+|www.\\.S+\")\n",
    "    data = url_pattern.sub(r\"\",data)\n",
    "    \n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "    \n",
    "    translator = str.maketrans(\" \",\" \",english_punctuations)\n",
    "    data = data.translate(translator)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love u guys r the best ', 'im meeting up with one of my besties tonight cant wait  girl talk', 'thanks for the twitter add sunisa i got to meet you once at a hin show here in the dc area and you were a sweetheart ', 'being sick can be really cheap when it hurts too much to eat real food plus your friends make you soup', 'he has that effect on everyone ']\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list \n",
    "text_list = combined[\"text\"].values.tolist()\n",
    "\n",
    "for i in range(len(text_list)):\n",
    "    temp.append(clean_data(text_list[i]))\n",
    "print(temp[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['love', 'guys', 'the', 'best'], ['im', 'meeting', 'up', 'with', 'one', 'of', 'my', 'besties', 'tonight', 'cant', 'wait', 'girl', 'talk'], ['thanks', 'for', 'the', 'twitter', 'add', 'sunisa', 'got', 'to', 'meet', 'you', 'once', 'at', 'hin', 'show', 'here', 'in', 'the', 'dc', 'area', 'and', 'you', 'were', 'sweetheart'], ['being', 'sick', 'can', 'be', 'really', 'cheap', 'when', 'it', 'hurts', 'too', 'much', 'to', 'eat', 'real', 'food', 'plus', 'your', 'friends', 'make', 'you', 'soup'], ['he', 'has', 'that', 'effect', 'on', 'everyone'], ['you', 'can', 'tell', 'him', 'that', 'just', 'burst', 'out', 'laughing', 'really', 'loud', 'because', 'of', 'that', 'thanks', 'for', 'making', 'me', 'come', 'out', 'of', 'my', 'sulk'], ['thans', 'for', 'your', 'response', 'ihad', 'already', 'find', 'this', 'answer'], ['am', 'so', 'jealous', 'hope', 'you', 'had', 'great', 'time', 'in', 'vegas', 'how', 'did', 'you', 'like', 'the', 'acms', 'love', 'your', 'show'], ['ah', 'congrats', 'mr', 'fletcher', 'for', 'finally', 'joining', 'twitter'], ['responded', 'stupid', 'cat', 'is', 'helping', 'me', 'type', 'forgive', 'errors']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True)) #deacc=True removes punctuations\n",
    "        \n",
    "data_words = list(sent_to_words(temp))\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "gensim.utils.simple_preprocess(doc, deacc=False, min_len=2, max_len=15)\n",
    "    \n",
    "Convert a document into a list of tokens.\n",
    "\n",
    "This lowercases, tokenizes, de-accents (optional). – the output are final tokens = unicode strings, that won’t be processed any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love guys the best', 'im meeting up with one of my besties tonight cant wait girl talk', 'thanks for the twitter add sunisa got to meet you once at hin show here in the dc area and you were sweetheart', 'being sick can be really cheap when it hurts too much to eat real food plus your friends make you soup', 'he has that effect on everyone']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(combined[\"target\"])\n",
    "labels = tf.keras.utils.to_categorical(labels,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sequencing and splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming text data into 3D fload data via Keras Tokenizer and pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_sequences: \n",
    "This function transforms a list (of length `num_samples`) of sequences (lists of integers) into a 2D Numpy array of shape `(num_samples, num_timesteps)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  212    2  172]\n",
      " [   0    0    0 ...  138  287  317]\n",
      " [   0    0    0 ...    5  125 2888]\n",
      " ...\n",
      " [   0    0    0 ...  147    5  257]\n",
      " [   0    0    0 ...    9    3  469]\n",
      " [   0    0    0 ...  482   20   13]]\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,   48,  212,\n",
       "           2,  172],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          11,  549,   26,   19,   51,   10,    3, 3935,  115,   45,  138,\n",
       "         287,  317]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 10000 30000 10000\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(tweets,labels,random_state=1000000)\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    1  721  153]\n",
      " [   0    0    0 ...    1  912   16]\n",
      " [   0    0    0 ...    7 2483   92]\n",
      " ...\n",
      " [   0    0    0 ...  305    1    5]\n",
      " [   0    0    0 ...    0    0    4]\n",
      " [   0    0    0 ...    5  296 2651]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  182    9   39]\n",
      " [   0    0    0 ...  636    4    7]\n",
      " [   0    0    0 ...   22  649  185]\n",
      " ...\n",
      " [   0    0    0 ...   78   58  302]\n",
      " [   0    0    0 ...  452   84  780]\n",
      " [   0    0    0 ...  108 1601   59]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 different models has been used:\n",
    "* Single LSTM layer model\n",
    "* Bidirectional LSTM model\n",
    "* 1D convolutional model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single LSTM layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6373 - loss: 0.6208\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76240, saving model to best_model1.keras\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 36ms/step - accuracy: 0.6374 - loss: 0.6206 - val_accuracy: 0.7624 - val_loss: 0.5006\n",
      "Epoch 2/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7865 - loss: 0.4631\n",
      "Epoch 2: val_accuracy improved from 0.76240 to 0.76920, saving model to best_model1.keras\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.7865 - loss: 0.4631 - val_accuracy: 0.7692 - val_loss: 0.4916\n",
      "Epoch 3/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8005 - loss: 0.4419\n",
      "Epoch 3: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8005 - loss: 0.4419 - val_accuracy: 0.7683 - val_loss: 0.4937\n",
      "Epoch 4/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8130 - loss: 0.4242\n",
      "Epoch 4: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8130 - loss: 0.4242 - val_accuracy: 0.7626 - val_loss: 0.4999\n",
      "Epoch 5/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8174 - loss: 0.4117\n",
      "Epoch 5: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8174 - loss: 0.4117 - val_accuracy: 0.7664 - val_loss: 0.5036\n",
      "Epoch 6/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8259 - loss: 0.3992\n",
      "Epoch 6: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.8259 - loss: 0.3992 - val_accuracy: 0.7645 - val_loss: 0.5140\n",
      "Epoch 7/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8320 - loss: 0.3889\n",
      "Epoch 7: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8320 - loss: 0.3889 - val_accuracy: 0.7647 - val_loss: 0.5105\n",
      "Epoch 8/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8357 - loss: 0.3831\n",
      "Epoch 8: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.8357 - loss: 0.3831 - val_accuracy: 0.7617 - val_loss: 0.5232\n",
      "Epoch 9/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8442 - loss: 0.3659\n",
      "Epoch 9: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.8442 - loss: 0.3659 - val_accuracy: 0.7628 - val_loss: 0.5288\n",
      "Epoch 10/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8509 - loss: 0.3548\n",
      "Epoch 10: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8509 - loss: 0.3548 - val_accuracy: 0.7634 - val_loss: 0.5384\n",
      "Epoch 11/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8521 - loss: 0.3527\n",
      "Epoch 11: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8521 - loss: 0.3527 - val_accuracy: 0.7615 - val_loss: 0.5558\n",
      "Epoch 12/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8550 - loss: 0.3416\n",
      "Epoch 12: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 39ms/step - accuracy: 0.8550 - loss: 0.3416 - val_accuracy: 0.7602 - val_loss: 0.5562\n",
      "Epoch 13/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8594 - loss: 0.3310\n",
      "Epoch 13: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.8594 - loss: 0.3310 - val_accuracy: 0.7568 - val_loss: 0.5527\n",
      "Epoch 14/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8592 - loss: 0.3347\n",
      "Epoch 14: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8592 - loss: 0.3347 - val_accuracy: 0.7564 - val_loss: 0.5929\n",
      "Epoch 15/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8634 - loss: 0.3248\n",
      "Epoch 15: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8634 - loss: 0.3248 - val_accuracy: 0.7522 - val_loss: 0.5872\n",
      "Epoch 16/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8672 - loss: 0.3144\n",
      "Epoch 16: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 37ms/step - accuracy: 0.8672 - loss: 0.3144 - val_accuracy: 0.7549 - val_loss: 0.5765\n",
      "Epoch 17/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8721 - loss: 0.3038\n",
      "Epoch 17: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 37ms/step - accuracy: 0.8721 - loss: 0.3038 - val_accuracy: 0.7549 - val_loss: 0.5943\n",
      "Epoch 18/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8752 - loss: 0.2982\n",
      "Epoch 18: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 37ms/step - accuracy: 0.8752 - loss: 0.2982 - val_accuracy: 0.7535 - val_loss: 0.6243\n",
      "Epoch 19/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8725 - loss: 0.2973\n",
      "Epoch 19: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 37ms/step - accuracy: 0.8725 - loss: 0.2973 - val_accuracy: 0.7540 - val_loss: 0.6527\n",
      "Epoch 20/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8840 - loss: 0.2816\n",
      "Epoch 20: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8840 - loss: 0.2816 - val_accuracy: 0.7526 - val_loss: 0.6440\n",
      "Epoch 21/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8810 - loss: 0.2862\n",
      "Epoch 21: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8810 - loss: 0.2862 - val_accuracy: 0.7459 - val_loss: 0.6398\n",
      "Epoch 22/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8827 - loss: 0.2776\n",
      "Epoch 22: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8827 - loss: 0.2776 - val_accuracy: 0.7475 - val_loss: 0.6537\n",
      "Epoch 23/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8844 - loss: 0.2716\n",
      "Epoch 23: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8844 - loss: 0.2716 - val_accuracy: 0.7509 - val_loss: 0.6921\n",
      "Epoch 24/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8829 - loss: 0.2736\n",
      "Epoch 24: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8829 - loss: 0.2736 - val_accuracy: 0.7450 - val_loss: 0.7126\n",
      "Epoch 25/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8895 - loss: 0.2666\n",
      "Epoch 25: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.8895 - loss: 0.2666 - val_accuracy: 0.7452 - val_loss: 0.6845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8881 - loss: 0.2663\n",
      "Epoch 26: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.8881 - loss: 0.2664 - val_accuracy: 0.7472 - val_loss: 0.7319\n",
      "Epoch 27/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8919 - loss: 0.2589\n",
      "Epoch 27: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.8919 - loss: 0.2589 - val_accuracy: 0.7452 - val_loss: 0.7352\n",
      "Epoch 28/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8877 - loss: 0.2622\n",
      "Epoch 28: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8877 - loss: 0.2622 - val_accuracy: 0.7450 - val_loss: 0.7321\n",
      "Epoch 29/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8916 - loss: 0.2595\n",
      "Epoch 29: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8916 - loss: 0.2595 - val_accuracy: 0.7451 - val_loss: 0.7620\n",
      "Epoch 30/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8958 - loss: 0.2473\n",
      "Epoch 30: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8958 - loss: 0.2474 - val_accuracy: 0.7444 - val_loss: 0.7730\n",
      "Epoch 31/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8943 - loss: 0.2505\n",
      "Epoch 31: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8943 - loss: 0.2505 - val_accuracy: 0.7416 - val_loss: 0.7833\n",
      "Epoch 32/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8992 - loss: 0.2404\n",
      "Epoch 32: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 39ms/step - accuracy: 0.8992 - loss: 0.2404 - val_accuracy: 0.7398 - val_loss: 0.7779\n",
      "Epoch 33/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8985 - loss: 0.2412\n",
      "Epoch 33: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8985 - loss: 0.2412 - val_accuracy: 0.7407 - val_loss: 0.7637\n",
      "Epoch 34/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8996 - loss: 0.2370\n",
      "Epoch 34: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.8996 - loss: 0.2370 - val_accuracy: 0.7423 - val_loss: 0.8425\n",
      "Epoch 35/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9038 - loss: 0.2319\n",
      "Epoch 35: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.9038 - loss: 0.2319 - val_accuracy: 0.7418 - val_loss: 0.8223\n",
      "Epoch 36/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8997 - loss: 0.2332\n",
      "Epoch 36: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8997 - loss: 0.2332 - val_accuracy: 0.7396 - val_loss: 0.8173\n",
      "Epoch 37/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9008 - loss: 0.2312\n",
      "Epoch 37: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9008 - loss: 0.2312 - val_accuracy: 0.7411 - val_loss: 0.8626\n",
      "Epoch 38/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9052 - loss: 0.2248\n",
      "Epoch 38: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9052 - loss: 0.2248 - val_accuracy: 0.7420 - val_loss: 0.8497\n",
      "Epoch 39/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9021 - loss: 0.2305\n",
      "Epoch 39: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9021 - loss: 0.2305 - val_accuracy: 0.7404 - val_loss: 0.8295\n",
      "Epoch 40/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9046 - loss: 0.2308\n",
      "Epoch 40: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9046 - loss: 0.2308 - val_accuracy: 0.7387 - val_loss: 0.8449\n",
      "Epoch 41/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9005 - loss: 0.2366\n",
      "Epoch 41: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9005 - loss: 0.2367 - val_accuracy: 0.7371 - val_loss: 0.7876\n",
      "Epoch 42/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8883 - loss: 0.2606\n",
      "Epoch 42: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8883 - loss: 0.2606 - val_accuracy: 0.7392 - val_loss: 0.8050\n",
      "Epoch 43/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8944 - loss: 0.2448\n",
      "Epoch 43: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.8944 - loss: 0.2448 - val_accuracy: 0.7410 - val_loss: 0.8403\n",
      "Epoch 44/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9018 - loss: 0.2338\n",
      "Epoch 44: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9018 - loss: 0.2338 - val_accuracy: 0.7366 - val_loss: 0.8406\n",
      "Epoch 45/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9058 - loss: 0.2241\n",
      "Epoch 45: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 37ms/step - accuracy: 0.9058 - loss: 0.2241 - val_accuracy: 0.7371 - val_loss: 0.8852\n",
      "Epoch 46/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9041 - loss: 0.2212\n",
      "Epoch 46: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9041 - loss: 0.2212 - val_accuracy: 0.7380 - val_loss: 0.8836\n",
      "Epoch 47/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9089 - loss: 0.2227\n",
      "Epoch 47: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9089 - loss: 0.2227 - val_accuracy: 0.7405 - val_loss: 0.9466\n",
      "Epoch 48/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9050 - loss: 0.2192\n",
      "Epoch 48: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9050 - loss: 0.2192 - val_accuracy: 0.7372 - val_loss: 0.9014\n",
      "Epoch 49/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.2185\n",
      "Epoch 49: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9062 - loss: 0.2185 - val_accuracy: 0.7369 - val_loss: 0.9124\n",
      "Epoch 50/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9108 - loss: 0.2122\n",
      "Epoch 50: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 36ms/step - accuracy: 0.9108 - loss: 0.2123 - val_accuracy: 0.7326 - val_loss: 0.8874\n",
      "Epoch 51/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9114 - loss: 0.2103\n",
      "Epoch 51: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9114 - loss: 0.2103 - val_accuracy: 0.7375 - val_loss: 0.9108\n",
      "Epoch 52/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9075 - loss: 0.2186\n",
      "Epoch 52: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9075 - loss: 0.2186 - val_accuracy: 0.7303 - val_loss: 0.9085\n",
      "Epoch 53/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9102 - loss: 0.2107\n",
      "Epoch 53: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9102 - loss: 0.2107 - val_accuracy: 0.7338 - val_loss: 0.9273\n",
      "Epoch 54/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9151 - loss: 0.2056\n",
      "Epoch 54: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9151 - loss: 0.2056 - val_accuracy: 0.7375 - val_loss: 0.9452\n",
      "Epoch 55/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9153 - loss: 0.1999\n",
      "Epoch 55: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 36ms/step - accuracy: 0.9153 - loss: 0.1999 - val_accuracy: 0.7353 - val_loss: 0.9291\n",
      "Epoch 56/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9153 - loss: 0.2022\n",
      "Epoch 56: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9153 - loss: 0.2022 - val_accuracy: 0.7345 - val_loss: 0.9203\n",
      "Epoch 57/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9139 - loss: 0.2071\n",
      "Epoch 57: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9139 - loss: 0.2071 - val_accuracy: 0.7319 - val_loss: 0.9417\n",
      "Epoch 58/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9129 - loss: 0.2057\n",
      "Epoch 58: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9129 - loss: 0.2057 - val_accuracy: 0.7335 - val_loss: 0.9702\n",
      "Epoch 59/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9161 - loss: 0.1973\n",
      "Epoch 59: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9161 - loss: 0.1973 - val_accuracy: 0.7337 - val_loss: 0.9881\n",
      "Epoch 60/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9148 - loss: 0.1982\n",
      "Epoch 60: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9148 - loss: 0.1982 - val_accuracy: 0.7349 - val_loss: 0.9614\n",
      "Epoch 61/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9173 - loss: 0.1987\n",
      "Epoch 61: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step - accuracy: 0.9173 - loss: 0.1988 - val_accuracy: 0.7338 - val_loss: 0.9742\n",
      "Epoch 62/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9159 - loss: 0.1976\n",
      "Epoch 62: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9159 - loss: 0.1976 - val_accuracy: 0.7359 - val_loss: 0.9645\n",
      "Epoch 63/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9188 - loss: 0.1967\n",
      "Epoch 63: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 36ms/step - accuracy: 0.9188 - loss: 0.1967 - val_accuracy: 0.7374 - val_loss: 0.9869\n",
      "Epoch 64/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9157 - loss: 0.1943\n",
      "Epoch 64: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9157 - loss: 0.1943 - val_accuracy: 0.7327 - val_loss: 0.9746\n",
      "Epoch 65/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9180 - loss: 0.2014\n",
      "Epoch 65: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9180 - loss: 0.2014 - val_accuracy: 0.7344 - val_loss: 0.9835\n",
      "Epoch 66/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9155 - loss: 0.2008\n",
      "Epoch 66: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9155 - loss: 0.2008 - val_accuracy: 0.7317 - val_loss: 0.9742\n",
      "Epoch 67/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9202 - loss: 0.1899\n",
      "Epoch 67: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 36ms/step - accuracy: 0.9202 - loss: 0.1899 - val_accuracy: 0.7361 - val_loss: 0.9799\n",
      "Epoch 68/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9186 - loss: 0.1924\n",
      "Epoch 68: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.9186 - loss: 0.1924 - val_accuracy: 0.7339 - val_loss: 0.9809\n",
      "Epoch 69/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9175 - loss: 0.1922\n",
      "Epoch 69: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.9175 - loss: 0.1922 - val_accuracy: 0.7389 - val_loss: 1.0165\n",
      "Epoch 70/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9173 - loss: 0.1955\n",
      "Epoch 70: val_accuracy did not improve from 0.76920\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 39ms/step - accuracy: 0.9173 - loss: 0.1955 - val_accuracy: 0.7354 - val_loss: 1.0109\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words,20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model1.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "#Creating checkpoints to examination on loss and accruracy\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.keras\",monitor=\"val_accuracy\",verbose=1,save_best_only=True,mode=\"auto\",save_weights_only=False)\n",
    "history = model1.fit(X_train,y_train,epochs=70,validation_data=(X_test,y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6409 - loss: 0.6200\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76560, saving model to best_model2.keras\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 66ms/step - accuracy: 0.6410 - loss: 0.6200 - val_accuracy: 0.7656 - val_loss: 0.4928\n",
      "Epoch 2/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7852 - loss: 0.4689\n",
      "Epoch 2: val_accuracy improved from 0.76560 to 0.77450, saving model to best_model2.keras\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.7852 - loss: 0.4689 - val_accuracy: 0.7745 - val_loss: 0.4795\n",
      "Epoch 3/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8016 - loss: 0.4402\n",
      "Epoch 3: val_accuracy improved from 0.77450 to 0.77620, saving model to best_model2.keras\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8016 - loss: 0.4402 - val_accuracy: 0.7762 - val_loss: 0.4789\n",
      "Epoch 4/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8090 - loss: 0.4243\n",
      "Epoch 4: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8090 - loss: 0.4243 - val_accuracy: 0.7733 - val_loss: 0.4804\n",
      "Epoch 5/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8157 - loss: 0.4042\n",
      "Epoch 5: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.8157 - loss: 0.4042 - val_accuracy: 0.7727 - val_loss: 0.4886\n",
      "Epoch 6/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8250 - loss: 0.3937\n",
      "Epoch 6: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8250 - loss: 0.3937 - val_accuracy: 0.7697 - val_loss: 0.4960\n",
      "Epoch 7/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8356 - loss: 0.3782\n",
      "Epoch 7: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8356 - loss: 0.3782 - val_accuracy: 0.7725 - val_loss: 0.4972\n",
      "Epoch 8/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8364 - loss: 0.3646\n",
      "Epoch 8: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8364 - loss: 0.3647 - val_accuracy: 0.7685 - val_loss: 0.5070\n",
      "Epoch 9/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8404 - loss: 0.3597\n",
      "Epoch 9: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8404 - loss: 0.3597 - val_accuracy: 0.7656 - val_loss: 0.5172\n",
      "Epoch 10/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8456 - loss: 0.3453\n",
      "Epoch 10: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8456 - loss: 0.3453 - val_accuracy: 0.7654 - val_loss: 0.5325\n",
      "Epoch 11/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8476 - loss: 0.3476\n",
      "Epoch 11: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8476 - loss: 0.3476 - val_accuracy: 0.7670 - val_loss: 0.5375\n",
      "Epoch 12/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8566 - loss: 0.3288\n",
      "Epoch 12: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8566 - loss: 0.3288 - val_accuracy: 0.7592 - val_loss: 0.5562\n",
      "Epoch 13/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8613 - loss: 0.3215\n",
      "Epoch 13: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8613 - loss: 0.3215 - val_accuracy: 0.7647 - val_loss: 0.5739\n",
      "Epoch 14/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8616 - loss: 0.3185\n",
      "Epoch 14: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8616 - loss: 0.3185 - val_accuracy: 0.7637 - val_loss: 0.5971\n",
      "Epoch 15/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8677 - loss: 0.3046\n",
      "Epoch 15: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8677 - loss: 0.3046 - val_accuracy: 0.7608 - val_loss: 0.5981\n",
      "Epoch 16/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8679 - loss: 0.3019\n",
      "Epoch 16: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8679 - loss: 0.3019 - val_accuracy: 0.7622 - val_loss: 0.6225\n",
      "Epoch 17/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8763 - loss: 0.2844\n",
      "Epoch 17: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8763 - loss: 0.2844 - val_accuracy: 0.7603 - val_loss: 0.6256\n",
      "Epoch 18/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8773 - loss: 0.2805\n",
      "Epoch 18: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8773 - loss: 0.2805 - val_accuracy: 0.7595 - val_loss: 0.6289\n",
      "Epoch 19/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8814 - loss: 0.2757\n",
      "Epoch 19: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8814 - loss: 0.2757 - val_accuracy: 0.7519 - val_loss: 0.6597\n",
      "Epoch 20/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8824 - loss: 0.2695\n",
      "Epoch 20: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8824 - loss: 0.2696 - val_accuracy: 0.7507 - val_loss: 0.6704\n",
      "Epoch 21/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8863 - loss: 0.2668\n",
      "Epoch 21: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8863 - loss: 0.2668 - val_accuracy: 0.7547 - val_loss: 0.6862\n",
      "Epoch 22/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8848 - loss: 0.2660\n",
      "Epoch 22: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8848 - loss: 0.2660 - val_accuracy: 0.7524 - val_loss: 0.7066\n",
      "Epoch 23/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8890 - loss: 0.2580\n",
      "Epoch 23: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8890 - loss: 0.2580 - val_accuracy: 0.7516 - val_loss: 0.7368\n",
      "Epoch 24/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8899 - loss: 0.2528\n",
      "Epoch 24: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8899 - loss: 0.2528 - val_accuracy: 0.7493 - val_loss: 0.7112\n",
      "Epoch 25/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8918 - loss: 0.2445\n",
      "Epoch 25: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8918 - loss: 0.2445 - val_accuracy: 0.7470 - val_loss: 0.7323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8990 - loss: 0.2392\n",
      "Epoch 26: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 63ms/step - accuracy: 0.8990 - loss: 0.2392 - val_accuracy: 0.7448 - val_loss: 0.7604\n",
      "Epoch 27/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8951 - loss: 0.2443\n",
      "Epoch 27: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.8951 - loss: 0.2443 - val_accuracy: 0.7508 - val_loss: 0.7866\n",
      "Epoch 28/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8964 - loss: 0.2408\n",
      "Epoch 28: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.8964 - loss: 0.2408 - val_accuracy: 0.7485 - val_loss: 0.7889\n",
      "Epoch 29/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9020 - loss: 0.2322\n",
      "Epoch 29: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9020 - loss: 0.2322 - val_accuracy: 0.7542 - val_loss: 0.8021\n",
      "Epoch 30/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9056 - loss: 0.2291\n",
      "Epoch 30: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9056 - loss: 0.2291 - val_accuracy: 0.7469 - val_loss: 0.8018\n",
      "Epoch 31/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9055 - loss: 0.2244\n",
      "Epoch 31: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.9055 - loss: 0.2244 - val_accuracy: 0.7452 - val_loss: 0.7867\n",
      "Epoch 32/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9049 - loss: 0.2225\n",
      "Epoch 32: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.9049 - loss: 0.2225 - val_accuracy: 0.7462 - val_loss: 0.8257\n",
      "Epoch 33/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9113 - loss: 0.2135\n",
      "Epoch 33: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9113 - loss: 0.2135 - val_accuracy: 0.7439 - val_loss: 0.8310\n",
      "Epoch 34/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9052 - loss: 0.2171\n",
      "Epoch 34: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9052 - loss: 0.2172 - val_accuracy: 0.7383 - val_loss: 0.8307\n",
      "Epoch 35/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9076 - loss: 0.2144\n",
      "Epoch 35: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9076 - loss: 0.2144 - val_accuracy: 0.7441 - val_loss: 0.8380\n",
      "Epoch 36/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9110 - loss: 0.2130\n",
      "Epoch 36: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9110 - loss: 0.2130 - val_accuracy: 0.7425 - val_loss: 0.8510\n",
      "Epoch 37/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9141 - loss: 0.2088\n",
      "Epoch 37: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9141 - loss: 0.2088 - val_accuracy: 0.7436 - val_loss: 0.8469\n",
      "Epoch 38/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9128 - loss: 0.2075\n",
      "Epoch 38: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9128 - loss: 0.2075 - val_accuracy: 0.7410 - val_loss: 0.8505\n",
      "Epoch 39/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9136 - loss: 0.2047\n",
      "Epoch 39: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9136 - loss: 0.2047 - val_accuracy: 0.7446 - val_loss: 0.8972\n",
      "Epoch 40/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9144 - loss: 0.2033\n",
      "Epoch 40: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9144 - loss: 0.2033 - val_accuracy: 0.7381 - val_loss: 0.8523\n",
      "Epoch 41/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9153 - loss: 0.2002\n",
      "Epoch 41: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9153 - loss: 0.2003 - val_accuracy: 0.7438 - val_loss: 0.8986\n",
      "Epoch 42/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9197 - loss: 0.1906\n",
      "Epoch 42: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9197 - loss: 0.1906 - val_accuracy: 0.7429 - val_loss: 0.9048\n",
      "Epoch 43/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9167 - loss: 0.1958\n",
      "Epoch 43: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9167 - loss: 0.1958 - val_accuracy: 0.7442 - val_loss: 0.9126\n",
      "Epoch 44/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9198 - loss: 0.1969\n",
      "Epoch 44: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9198 - loss: 0.1969 - val_accuracy: 0.7418 - val_loss: 0.9125\n",
      "Epoch 45/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9189 - loss: 0.1933\n",
      "Epoch 45: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9189 - loss: 0.1933 - val_accuracy: 0.7400 - val_loss: 0.8945\n",
      "Epoch 46/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9195 - loss: 0.1904\n",
      "Epoch 46: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9195 - loss: 0.1904 - val_accuracy: 0.7418 - val_loss: 0.9446\n",
      "Epoch 47/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9148 - loss: 0.1976\n",
      "Epoch 47: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9148 - loss: 0.1976 - val_accuracy: 0.7426 - val_loss: 0.9412\n",
      "Epoch 48/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9192 - loss: 0.1863\n",
      "Epoch 48: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9192 - loss: 0.1863 - val_accuracy: 0.7386 - val_loss: 0.9403\n",
      "Epoch 49/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9239 - loss: 0.1815\n",
      "Epoch 49: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.9239 - loss: 0.1815 - val_accuracy: 0.7359 - val_loss: 0.9505\n",
      "Epoch 50/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9218 - loss: 0.1865\n",
      "Epoch 50: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9218 - loss: 0.1866 - val_accuracy: 0.7412 - val_loss: 0.9397\n",
      "Epoch 51/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9209 - loss: 0.1896\n",
      "Epoch 51: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9209 - loss: 0.1896 - val_accuracy: 0.7380 - val_loss: 0.9651\n",
      "Epoch 52/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9231 - loss: 0.1867\n",
      "Epoch 52: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9231 - loss: 0.1867 - val_accuracy: 0.7411 - val_loss: 0.9733\n",
      "Epoch 53/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9243 - loss: 0.1824\n",
      "Epoch 53: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.9243 - loss: 0.1824 - val_accuracy: 0.7375 - val_loss: 1.0292\n",
      "Epoch 54/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9222 - loss: 0.1830\n",
      "Epoch 54: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.9222 - loss: 0.1830 - val_accuracy: 0.7377 - val_loss: 0.9859\n",
      "Epoch 55/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9222 - loss: 0.1844\n",
      "Epoch 55: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9222 - loss: 0.1844 - val_accuracy: 0.7382 - val_loss: 1.0113\n",
      "Epoch 56/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9252 - loss: 0.1776\n",
      "Epoch 56: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9252 - loss: 0.1776 - val_accuracy: 0.7375 - val_loss: 1.0042\n",
      "Epoch 57/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9249 - loss: 0.1809\n",
      "Epoch 57: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9249 - loss: 0.1809 - val_accuracy: 0.7408 - val_loss: 1.0180\n",
      "Epoch 58/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9259 - loss: 0.1757\n",
      "Epoch 58: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 63ms/step - accuracy: 0.9259 - loss: 0.1757 - val_accuracy: 0.7418 - val_loss: 0.9523\n",
      "Epoch 59/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9257 - loss: 0.1771\n",
      "Epoch 59: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9257 - loss: 0.1771 - val_accuracy: 0.7394 - val_loss: 1.0111\n",
      "Epoch 60/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9257 - loss: 0.1799\n",
      "Epoch 60: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9257 - loss: 0.1799 - val_accuracy: 0.7378 - val_loss: 1.0129\n",
      "Epoch 61/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9263 - loss: 0.1759\n",
      "Epoch 61: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9263 - loss: 0.1759 - val_accuracy: 0.7407 - val_loss: 1.0363\n",
      "Epoch 62/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9276 - loss: 0.1725\n",
      "Epoch 62: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9276 - loss: 0.1725 - val_accuracy: 0.7390 - val_loss: 0.9972\n",
      "Epoch 63/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9262 - loss: 0.1778\n",
      "Epoch 63: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9262 - loss: 0.1778 - val_accuracy: 0.7369 - val_loss: 1.0149\n",
      "Epoch 64/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9322 - loss: 0.1660\n",
      "Epoch 64: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9321 - loss: 0.1660 - val_accuracy: 0.7408 - val_loss: 1.0135\n",
      "Epoch 65/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9294 - loss: 0.1677\n",
      "Epoch 65: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.9294 - loss: 0.1677 - val_accuracy: 0.7369 - val_loss: 1.0178\n",
      "Epoch 66/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9308 - loss: 0.1672\n",
      "Epoch 66: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9308 - loss: 0.1672 - val_accuracy: 0.7383 - val_loss: 1.0185\n",
      "Epoch 67/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9289 - loss: 0.1704\n",
      "Epoch 67: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9289 - loss: 0.1704 - val_accuracy: 0.7391 - val_loss: 1.0239\n",
      "Epoch 68/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9269 - loss: 0.1710\n",
      "Epoch 68: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9269 - loss: 0.1710 - val_accuracy: 0.7360 - val_loss: 1.0347\n",
      "Epoch 69/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9285 - loss: 0.1682\n",
      "Epoch 69: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9285 - loss: 0.1682 - val_accuracy: 0.7436 - val_loss: 1.0538\n",
      "Epoch 70/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9323 - loss: 0.1673\n",
      "Epoch 70: val_accuracy did not improve from 0.77620\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9323 - loss: 0.1673 - val_accuracy: 0.7404 - val_loss: 1.0292\n"
     ]
    }
   ],
   "source": [
    "model2= Sequential()\n",
    "model2.add(layers.Embedding(max_words,40,input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model2.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics= [\"accuracy\"] )\n",
    "#Creating checkpoints to examination on loss and accruracy\n",
    "checkpoint2= ModelCheckpoint(\"best_model2.keras\",monitor= \"val_accuracy\",verbose=1,save_best_only=True,mode=\"auto\",save_weights_only=False)\n",
    "history= model2.fit(X_train,y_train,epochs= 70, validation_data=(X_test,y_test),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m931/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5049 - loss: 0.9033\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50480, saving model to best_model3.keras\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5048 - loss: 0.9021 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 2/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5041 - loss: 0.6948\n",
      "Epoch 2: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 3/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5058 - loss: 0.6948\n",
      "Epoch 3: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5058 - loss: 0.6948 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 4/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5017 - loss: 0.6949\n",
      "Epoch 4: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5017 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 5/70\n",
      "\u001b[1m932/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4973 - loss: 0.6949\n",
      "Epoch 5: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4973 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 6/70\n",
      "\u001b[1m927/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4993 - loss: 0.6949\n",
      "Epoch 6: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4993 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 7/70\n",
      "\u001b[1m927/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5033 - loss: 0.6949\n",
      "Epoch 7: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5033 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6951\n",
      "Epoch 8/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5015 - loss: 0.6949\n",
      "Epoch 8: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5015 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 9/70\n",
      "\u001b[1m935/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4990 - loss: 0.6949\n",
      "Epoch 9: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4990 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6952\n",
      "Epoch 10/70\n",
      "\u001b[1m926/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.6950\n",
      "Epoch 10: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.6950 - val_accuracy: 0.4952 - val_loss: 0.6951\n",
      "Epoch 11/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4940 - loss: 0.6950\n",
      "Epoch 11: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4940 - loss: 0.6950 - val_accuracy: 0.4952 - val_loss: 0.6951\n",
      "Epoch 12/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5052 - loss: 0.6948\n",
      "Epoch 12: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5052 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 13/70\n",
      "\u001b[1m931/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: 0.6949\n",
      "Epoch 13: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 14/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4957 - loss: 0.6949\n",
      "Epoch 14: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4957 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6951\n",
      "Epoch 15/70\n",
      "\u001b[1m935/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.6949\n",
      "Epoch 15: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 16/70\n",
      "\u001b[1m928/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4981 - loss: 0.6949\n",
      "Epoch 16: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4981 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 17/70\n",
      "\u001b[1m928/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4992 - loss: 0.6949\n",
      "Epoch 17: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4993 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6953\n",
      "Epoch 18/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4958 - loss: 0.6950\n",
      "Epoch 18: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4958 - loss: 0.6950 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 19/70\n",
      "\u001b[1m934/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4975 - loss: 0.6949\n",
      "Epoch 19: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4975 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6953\n",
      "Epoch 20/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4998 - loss: 0.6949\n",
      "Epoch 20: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4998 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 21/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4979 - loss: 0.6950\n",
      "Epoch 21: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4979 - loss: 0.6950 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 22/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5051 - loss: 0.6948\n",
      "Epoch 22: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5051 - loss: 0.6948 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 23/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4932 - loss: 0.6949\n",
      "Epoch 23: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4932 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 24/70\n",
      "\u001b[1m932/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 0.6949\n",
      "Epoch 24: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 25/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4986 - loss: 0.6949\n",
      "Epoch 25: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4986 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6951\n",
      "Epoch 26/70\n",
      "\u001b[1m927/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4941 - loss: 0.6949\n",
      "Epoch 26: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4942 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 27/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4990 - loss: 0.6949\n",
      "Epoch 27: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4990 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6953\n",
      "Epoch 28/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 0.6950\n",
      "Epoch 28: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 0.6950 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 29/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6949\n",
      "Epoch 29: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 30/70\n",
      "\u001b[1m932/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5060 - loss: 0.6948\n",
      "Epoch 30: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5060 - loss: 0.6948 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 31/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4956 - loss: 0.6949\n",
      "Epoch 31: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4957 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6952\n",
      "Epoch 32/70\n",
      "\u001b[1m937/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5037 - loss: 0.6949\n",
      "Epoch 32: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5037 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 33/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4981 - loss: 0.6949\n",
      "Epoch 33: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4981 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 34/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 0.6949\n",
      "Epoch 34: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6952\n",
      "Epoch 35/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6948\n",
      "Epoch 35: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5034 - loss: 0.6948 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 36/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4997 - loss: 0.6949\n",
      "Epoch 36: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4997 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 37/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5045 - loss: 0.6948\n",
      "Epoch 37: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5045 - loss: 0.6948 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 38/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5047 - loss: 0.6948\n",
      "Epoch 38: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5047 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 39/70\n",
      "\u001b[1m934/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4884 - loss: 0.6950\n",
      "Epoch 39: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4884 - loss: 0.6950 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 40/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5031 - loss: 0.6948\n",
      "Epoch 40: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5031 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 41/70\n",
      "\u001b[1m927/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6949\n",
      "Epoch 41: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 42/70\n",
      "\u001b[1m931/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4981 - loss: 0.6949\n",
      "Epoch 42: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4980 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 43/70\n",
      "\u001b[1m928/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5023 - loss: 0.6949\n",
      "Epoch 43: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5022 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 44/70\n",
      "\u001b[1m928/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5026 - loss: 0.6948\n",
      "Epoch 44: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5025 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 45/70\n",
      "\u001b[1m926/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5002 - loss: 0.6948\n",
      "Epoch 45: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 46/70\n",
      "\u001b[1m930/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5029 - loss: 0.6949\n",
      "Epoch 46: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5029 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 47/70\n",
      "\u001b[1m927/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4989 - loss: 0.6949\n",
      "Epoch 47: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 48/70\n",
      "\u001b[1m928/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4974 - loss: 0.6949\n",
      "Epoch 48: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4975 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6953\n",
      "Epoch 49/70\n",
      "\u001b[1m925/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 0.6949\n",
      "Epoch 49: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 50/70\n",
      "\u001b[1m934/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5049 - loss: 0.6948\n",
      "Epoch 50: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5049 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 51/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m931/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6949\n",
      "Epoch 51: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 52/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5036 - loss: 0.6948\n",
      "Epoch 52: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5036 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 53/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5034 - loss: 0.6948\n",
      "Epoch 53: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5034 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 54/70\n",
      "\u001b[1m930/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6949\n",
      "Epoch 54: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 55/70\n",
      "\u001b[1m930/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6949\n",
      "Epoch 55: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6952\n",
      "Epoch 56/70\n",
      "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5031 - loss: 0.6948\n",
      "Epoch 56: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5031 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 57/70\n",
      "\u001b[1m932/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5063 - loss: 0.6948\n",
      "Epoch 57: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5063 - loss: 0.6948 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 58/70\n",
      "\u001b[1m924/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 0.6949\n",
      "Epoch 58: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 59/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5031 - loss: 0.6949\n",
      "Epoch 59: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5031 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 60/70\n",
      "\u001b[1m928/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: 0.6947\n",
      "Epoch 60: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5073 - loss: 0.6947 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 61/70\n",
      "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 0.6949\n",
      "Epoch 61: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5001 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6948\n",
      "Epoch 62/70\n",
      "\u001b[1m934/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5066 - loss: 0.6948\n",
      "Epoch 62: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5066 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6948\n",
      "Epoch 63/70\n",
      "\u001b[1m936/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5024 - loss: 0.6949\n",
      "Epoch 63: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5024 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6950\n",
      "Epoch 64/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 0.6949\n",
      "Epoch 64: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5039 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 65/70\n",
      "\u001b[1m929/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 0.6949\n",
      "Epoch 65: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 66/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5006 - loss: 0.6949\n",
      "Epoch 66: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5006 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 67/70\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6948\n",
      "Epoch 67: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n",
      "Epoch 68/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4995 - loss: 0.6949\n",
      "Epoch 68: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4995 - loss: 0.6949 - val_accuracy: 0.5048 - val_loss: 0.6948\n",
      "Epoch 69/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5014 - loss: 0.6949\n",
      "Epoch 69: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5014 - loss: 0.6949 - val_accuracy: 0.4952 - val_loss: 0.6948\n",
      "Epoch 70/70\n",
      "\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5011 - loss: 0.6948\n",
      "Epoch 70: val_accuracy did not improve from 0.50480\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5011 - loss: 0.6948 - val_accuracy: 0.4952 - val_loss: 0.6949\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(max_words,40,input_length=max_len))\n",
    "model3.add(layers.Conv1D(20,6,activation=\"relu\",kernel_regularizer = regularizers.l1_l2(l1=2e-3,l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.MaxPooling1D(5))\n",
    "model3.add(layers.Conv1D(20,6,activation=\"relu\",kernel_regularizer = regularizers.l1_l2(l1=2e-3,l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.GlobalMaxPool1D())\n",
    "model3.add(layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model3.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics= [\"accuracy\"] )\n",
    "#Creating checkpoints to examination on loss and accruracy\n",
    "checkpoint3= ModelCheckpoint(\"best_model3.keras\",monitor= \"val_accuracy\",verbose=1,save_best_only=True,mode=\"auto\",save_weights_only=False)\n",
    "history= model3.fit(X_train,y_train,epochs= 70, validation_data=(X_test,y_test),callbacks=[checkpoint3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the validation accuracy best fitting model is Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "best_model = keras.models.load_model(\"best_model2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 5s - 15ms/step - accuracy: 0.8129 - loss: 0.4181\n",
      "Model Accuracy: 0.8129000067710876\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = best_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"Model Accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(predictions,decimals=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1),np.around(predictions,decimals = 0).argmax(axis=1))\n",
    "#argmax --> returns the indices of the maximum values along an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ">>> from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGsCAYAAABaczmOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJF0lEQVR4nO3deXxMZ9sH8N+QZLKZECQjEhFSqRAUfQmqVZEglKJqD4ImT1BJEXlqrwrR1lIlutqi1tKSomlIWpWqIsQWpAiyIZvs23n/8DjtVHBmDMmZ/L79nM87uc997rkm7zyu3Ne5zzkKQRAEEBERGYBaVR0AERGRvjCpERGRwWBSIyIig8GkRkREBoNJjYiIDAaTGhERGQwmNSIiMhhMakREZDCMqjqAB0pTL1R1CFRDmDl6VHUIVEOUldzS21ild/7S21jGDZrpbazqhjM1IiIyGNVmpkZERI9RUV7VEcgCkxoRkRwIFVUdgSyw/EhERAaDMzUiIjmo4ExNCiY1IiIZEFh+lITlRyIikmzJkiVQKBSYNm2a2FZUVISAgADUr18flpaWGDx4MNLT0zWOS05Ohre3N8zNzWFjY4MZM2agrKxMo09MTAzat28PpVIJZ2dnrF+/Xuv4mNSIiOSgokJ/m46OHz+OdevWoU2bNhrtgYGB2Lt3L3bs2IHY2FikpKRg0KBB4v7y8nJ4e3ujpKQER48exYYNG7B+/XrMnTtX7HP16lV4e3ujR48eiI+Px7Rp0zBhwgQcPHhQqxgV1eXJ17z4mp4XXnxNz4s+L74uuXFab2OZOLTV+pi8vDy0b98ea9aswaJFi9CuXTusWLECOTk5aNiwIbZs2YIhQ4YAAC5evIiWLVsiLi4OnTt3xv79+9GvXz+kpKTA1tYWABAeHo7g4GDcvn0bJiYmCA4ORmRkJM6ePSu+57Bhw5CdnY0DBw5IjpMzNSKiGqa4uBi5ubkaW3Fx8WOPCQgIgLe3Nzw8NP8oPHHiBEpLSzXaX3zxRTRp0gRxcXEAgLi4OLi5uYkJDQC8vLyQm5uLc+fOiX3+PbaXl5c4hlRMakREclBRrrctNDQUVlZWGltoaOgj33rr1q04efJkpX3S0tJgYmKCunXrarTb2toiLS1N7PPPhPZg/4N9j+uTm5uLwsJCyb8mrn4kIpIDPa5+DAkJQVBQkEabUqmstO+NGzfw7rvvIioqCqampnqL4VnhTI2IqIZRKpVQqVQa26OS2okTJ5CRkYH27dvDyMgIRkZGiI2NxapVq2BkZARbW1uUlJQgOztb47j09HSo1WoAgFqtfmg15IOfn9RHpVLBzMxM8mdjUiMikoMqWv3Ys2dPJCQkID4+Xtw6duyIkSNHiq+NjY0RHR0tHpOYmIjk5GS4u7sDANzd3ZGQkICMjAyxT1RUFFQqFVxdXcU+/xzjQZ8HY0jF8iMRkQxU1cXXderUQevWrTXaLCwsUL9+fbHd19cXQUFBsLa2hkqlwpQpU+Du7o7OnTsDADw9PeHq6orRo0cjLCwMaWlpmD17NgICAsQZop+fH1avXo2ZM2di/PjxOHToELZv347IyEit4mVSIyKip7J8+XLUqlULgwcPRnFxMby8vLBmzRpxf+3atbFv3z74+/vD3d0dFhYW8PHxwcKFC8U+Tk5OiIyMRGBgIFauXAl7e3t8+eWX8PLy0ioWXqdGNQ6vU6PnRZ/XqRVfPqq3sZQvdNHbWNUNZ2pERHLAez9KwoUiRERkMDhTIyKSAz75WhImNSIiOWD5URKWH4mIyGBwpkZEJAd88rUkTGpERHLA8qMkLD8SEZHB4EyNiEgOWH6UhEmNiEgGBIFL+qVg+ZGIiAwGZ2pERHLAhSKSMKkREckBz6lJwvIjEREZDM7UiIjkgOVHSZjUiIjkgDc0loTlRyIiMhicqRERyQHLj5IwqRERyQFXP0rC8iMRERkMztSIiOSA5UdJmNSIiOSA5UdJWH4kIiKDwZkaEZEccKYmCZMaEZEM8NEz0rD8SEREBoMzNSIiOWD5URImNSIiOeCSfklYfiQiIoPBmRoRkRyw/CgJkxoRkRyw/CgJy49ERGQwOFMjIpIDlh8lYVIjIpIDlh8lYfmRiIgMBmdqRERywPKjJExqRERywKQmCcuPRERkMDhTIyKSAy4UkYRJjYhIDlh+lITlRyIiMhicqRERyQHLj5IwqRERyQHLj5Kw/EhERAaDMzUiIjlg+VESJjUiIjlg+VESlh+JiMhgcKZGRCQHnKlJwqRGRCQHglDVEcgCy49ERGQwmNSIiOSgokJ/mxbWrl2LNm3aQKVSQaVSwd3dHfv37xf3v/baa1AoFBqbn5+fxhjJycnw9vaGubk5bGxsMGPGDJSVlWn0iYmJQfv27aFUKuHs7Iz169fr9Gti+ZGISA6q6Jyavb09lixZghdeeAGCIGDDhg0YMGAATp06hVatWgEAJk6ciIULF4rHmJubi6/Ly8vh7e0NtVqNo0ePIjU1FWPGjIGxsTEWL14MALh69Sq8vb3h5+eHiIgIREdHY8KECWjUqBG8vLy0ilchCLoVan/99VesW7cOSUlJ2LlzJxo3boxNmzbByckJ3bp103q80tQLuoRBpDUzR4+qDoFqiLKSW3obqzBijt7GMhv5wVMdb21tjWXLlsHX1xevvfYa2rVrhxUrVlTad//+/ejXrx9SUlJga2sLAAgPD0dwcDBu374NExMTBAcHIzIyEmfPnhWPGzZsGLKzs3HgwAGtYtOp/Lhr1y54eXnBzMwMp06dQnFxMQAgJydHzLxERKRHQoXetuLiYuTm5mpsD/4df5zy8nJs3boV+fn5cHd3F9sjIiLQoEEDtG7dGiEhISgoKBD3xcXFwc3NTUxoAODl5YXc3FycO3dO7OPhofnHppeXF+Li4rT+NemU1BYtWoTw8HB88cUXMDY2Ftu7du2KkydP6jIkERE9jh7PqYWGhsLKykpjCw0NfeRbJyQkwNLSEkqlEn5+fti9ezdcXV0BACNGjMDmzZtx+PBhhISEYNOmTRg1apR4bFpamkZCAyD+nJaW9tg+ubm5KCws1OrXpNM5tcTERHTv3v2hdisrK2RnZ+syJBERPSchISEICgrSaFMqlY/s7+Ligvj4eOTk5GDnzp3w8fFBbGwsXF1dMWnSJLGfm5sbGjVqhJ49eyIpKQnNmzd/Zp/hUXSaqanValy5cuWh9iNHjqBZs2ZPHRQREf2LIOhtUyqV4mrGB9vjkpqJiQmcnZ3RoUMHhIaGom3btli5cmWlfTt16gQAYo5Qq9VIT0/X6PPgZ7Va/dg+KpUKZmZmWv2adEpqEydOxLvvvotjx45BoVAgJSUFERERmD59Ovz9/XUZkoiIHqeKlvRXHkrFI8/BxcfHAwAaNWoEAHB3d0dCQgIyMjLEPlFRUVCpVGIJ093dHdHR0RrjREVFaZy3k0qn8uOsWbNQUVGBnj17oqCgAN27d4dSqcT06dMxZcoUXYYkIqJqKCQkBH369EGTJk1w7949bNmyBTExMTh48CCSkpKwZcsW9O3bF/Xr18eZM2cQGBiI7t27o02bNgAAT09PuLq6YvTo0QgLC0NaWhpmz56NgIAAcXbo5+eH1atXY+bMmRg/fjwOHTqE7du3IzIyUut4dV7SDwAlJSW4cuUK8vLy4OrqCktLS12H4pJ+em64pJ+eF70u6f9qut7GMvP9SHJfX19fREdHIzU1FVZWVmjTpg2Cg4PRq1cv3LhxA6NGjcLZs2eRn58PBwcHvPnmm5g9ezZUKpU4xvXr1+Hv74+YmBhYWFjAx8cHS5YsgZHR3/OqmJgYBAYG4vz587C3t8ecOXMwduxYrT+bTklt8+bNGDRokMYFdk+LSY2eFyY1el70mtS+DHpyJ4nMJnyit7GqG53OqQUGBsLGxgYjRozAjz/+iPLycn3HRUREpDWdklpqaiq2bt0KhUKBoUOHolGjRggICMDRo0f1HR8REQEQKgS9bYZMp6RmZGSEfv36ISIiAhkZGVi+fDmuXbuGHj16VMl1CUREBq8arX6szp76hsbm5ubw8vJCVlYWrl+/jgsXeG6MiIiqhs5JraCgALt37xbvqOzg4IDhw4dj586d+oyPiIiA+/dtpCfSKakNGzYM+/btg7m5OYYOHYo5c+bodJEcERFJZODnwvRFp6RWu3ZtbN++HV5eXqhdu7a+YyIiItKJTkktIiJC33EQEdHjGPgCD32RnNRWrVqFSZMmwdTUFKtWrXps36lTpz51YERERNqSfEcRJycn/Pnnn6hfvz6cnJwePaBCgb/++kvrQHhHEXpeeEcRel70eUeRgpV+ehvL/N1wvY1V3UieqV29erXS10RE9BzofpveGkWni68XLlyo8bjuBwoLC7Fw4cKnDoqIiEgXOiW1BQsWIC8v76H2goICLFiw4KmDMnRfRuxC69cGYsmnXz6z9xAEAau/3oLXBo1DB8+hmBA0F9dvpmj0mfzfD+ExdALa93oLrw0ah1kfLkfGncxnFhPpj6WlBT7+aAGSLh/DvZwr+DX2e3Ts0PaR/dVqG2zauBrnz/2KkqIb+Pij5/O/01e7u+OPYweQf+8vXDx/BGNGD9XYHzxzMuKORiLrbiJSbp7Grp1foUUL3pWoUryjiCQ6JTVBEKBQKB5qP336NKytrZ86KEOWcPEyduw9iBbNmz7VOJ998y3eD638ybMA8PW3uxGxax/mBvlhy9owmJmZ4p0ZC1BcXCL2+b+X3PDxvBnYt+kzLF8YjBspaQict/Sp4qLn4/N1H8HD4xWMHTcV7dp7IOrnWBw8sBV2dupK+yuVJrh9+y4Wh67E6TPn9RKDo6P9Y88ZNW3qgB++34jYmKPo8LInVn36JT5ftwyevV4V+3R/pTPWrt2Arq/0R+++w2FsZIz9kVtgbq7d045rhApBf5sB0yqp1atXD9bW1lAoFGjRogWsra3FzcrKCr169cLQoUOfPFANVVBQiFmLlmP+9ACoLC009uXey8PcsNV4ZcAYdOo7HOMD5+DiFd3OXQqCgE0792LS6KF4vVsnuDRvisUh7yLjTiaijxwT+4156w20beUCO7UNXmr9IiaMGIwz5y+htKzsqT4nPVumpqYY9GZfhIR8iF+PHENS0jUs/OATXEm6Br93xlR6zPXrNxH03jxs3rwTuTm5jxx7/LjhSDgTg7zcJJxNiIXfOz46x/nOpNG4ei0ZM4IX4uLFK1izdj12fReJd6dOFPt49x+FjZu24/z5Szhz5jzGT5gGR0d7dGjfRuf3pZpNq+vUVqxYAUEQMH78eCxYsABWVlbiPhMTEzRt2pR3FnmMRSs/R/fOHeDesS3WbdqusS9o/jKYKk2wdulc1LE0x/YfDmJC0FxEbl4DK1Udrd7nZmo67mRmwb3D3/8w1LG0QBvXFjh9PhF9e77y0DE5ufew7+dYtGv1IoyNnvqWoPQMGRnVhpGREYqKijXaiwqL0LXLyzqPO3z4m5g/bzqmTpuN+PizaNeuNdatXYb8ggJs2rRD6/E6d+qA6OgjGm0//RSDTz5+dOnTyur+gyUzs7K1fj+Dx9tkSaLVv14+Pvf/anNyckKXLl1gbGz8TIIyRD9G/4oLl5KwNfzhJ86ePHMeZy9exi+7N8DE5P7vdMZ/xuHQkWP4KfYo3urvpdV73cnMBgDUt66r0V6/nhXuZGZptH2ybgO+3f0jCouK0dbVBZ+Fvq/Ve9Hzl5eXj7i4P/H+f9/FhYuXkZ5+G8OGDUTnzh1wJemazuPOm/MeZgQvxJ49+wEA167dgGvLFpg0YZROSc1WbYOMjNsabRkZd2BlpYKpqSmKioo09ikUCnzy0QL89tsfOHcuUefPYbAMvGyoLzr9Sf7qq3/XxIuKilBSUqKx/5+P8a5McXExios1/8qsVVwCpdJEl3CqvdSM21iy+kt88dGCSj9jYtI1FBQWoesbozXai0tKcCMlDQBw4sw5+M38QNxXWlYGCAJ+io0T2+a9549+/zhfIcW4t9/EoL4eSEm/jbXrtyEkdCXWhM6u9JwpVR8+46biy88/xo3rJ1FWVoZTpxKwddsetNexbGdubgZnZyd8se5jrFu7TGw3MqqNnJx74s+n4w/BsYk9AIjfkezMS+L+I0eOod+/vsdSfbpqMVq1csGrPd7U6XgiQMekVlBQgJkzZ2L79u24e/fuQ/uf9CTs0NDQh1ZJzg76D+ZOn6xLONXe+cQkZGblYOjEvx/HXl5RgRNnzuPb3T9i6oRRaGhdD9+sWPTQsXX+d+6tlYszdn25XGzf/N0+ZNy5i6BJf5/zeDAza/C//3s3MxsN6/+9cOduVg5cnDUvnK9XV4V6dVVo6tAYzZrYw2PoBJw+n4h2rV586s9Nz85ff13H6x5DYG5uBpWqDtLSMrAlYi2u/pWs03iW//ueveM/A3/8cUpj3z//99z/jdFihaaxnRqHonehw8ue4v7Cwr9nX+lpGbCxaagxlo1NA+Tk5D40S1u5YhG8+3qgR89BuHUrVafPYOgEA1+1qC86JbUZM2bg8OHDWLt2LUaPHo3PPvsMt27dwrp167BkyZInHh8SEoKgoCCNtlqZhntBd+cObbH7a82VirOXfgqnJo3hO3wQbmdm4U5mFmrXroXGjWwrHcNUqUQT+0biz1Z1LJGfX6DR9oB9I1s0sK6H30+ewYsvNAMA5OUX4Mz5Sxj6Ru9Hxvng5jIlJaVaf0aqGgUFhSgoKETdulbw7PUqZoV8qNM4GRl3cOtWKpo5OeLbb3c/sl9y8t+rHcv+t6Ao6RElz9+PnUDv3q9rtHl4dMfvv5/QaFu5YhEGDuiNnr3ewrVrN3SKv0Zg+VESnZLa3r17sXHjRrz22msYN24cXnnlFTg7O8PR0REREREYOXLkY49XKpVQKpUabaX5hll6BAALczO80MxRo83MVIm6qjp4oZkjnJ2aoG0rF0ydHYogPx80tbdDxt0s/PL7n+jZrTNav+is1fspFAqMHtIfn2/aAUd7OzRuZIPVX22BTQNr9OzWCQBw5vwlnL14Ge3dWkJVxxI3UtLw6ddb4GCn5ixNBjx7vQqFQoHES0lwbt4US5bMQWJiEtZv2AYA+HDRLNjZNcK48e+Kx7Rt2woAYGFpgYYNrdG2bSuUlJTgwoXLAIAFCz/GiuUfICcnFwd/ioFSaYIO7dugXr26WLHyc61jXPf5JvzHfxyWhL6Pb9ZvRY/XuuGtIf3xxoC/V2h+umoxhg8biEGDx+PevTzY2t6f2eXk3HtoNkckhU5JLTMzE82a3Z8BqFQqZGbev2C3W7du8Pf31190NYRCocDapXOx8svNmLP0U2Rm56KBdV10aNMK9a2tnjxAJcYPfxOFRUWY/9Ea3MvLR3u3lggPmyue0zM1NcHPv/6Oz9ZvRWFhERrWr4eu/9ce78x7S1ysQtWXykqFDz+YBXv7RsjMzMZ3u3/EnLlLxdmTWm2LJg52GsecOP6T+Lpjh7YYMXwQrl27AecWnQEAX3/zLQoKC/FekD+WLpmN/PwCnD17ESt1vEnAtWs38MaAMfjoo/mYMtkXN2+mYtI7M/BTVKzYx9/vfvn8UPQujWPH+wZi479WCNd4XP0oieQbGv9TmzZt8Omnn+LVV1+Fh4cH2rVrh48++girVq1CWFgYbt68qXUgvKExPS+8oTE9L/q8oXH+wsdXwLRhMddwHx+m0x1Fxo0bh9OnTwMAZs2ahc8++wympqYIDAzEjBkz9BogERGRVDqVHwMDA8XXHh4euHjxIk6cOAFnZ2e0acM7ARAR6R1XP0qil1tHODo6wtHR8ckdiYhIN1z9KIlOSe1RT75WKBQwNTWFs7Mzunfvjtq1az9VcERERNrQKaktX74ct2/fRkFBAerVqwcAyMrKgrm5OSwtLZGRkYFmzZrh8OHDcHBw0GvAREQ1Elc/SqLTQpHFixfj5ZdfxuXLl3H37l3cvXsXly5dQqdOnbBy5UokJydDrVZrnHsjIqKnwEfPSKLTTG327NnYtWsXmjf/+2F+zs7O+OijjzB48GD89ddfCAsLw+DBg/UWKBER0ZPolNRSU1PFizz/qaysDGlp92/Aa2dnh3v37j3Uh4iItMd7P0qjU/mxR48eeOedd3Dq1N83Pj116hT8/f3x+uv37/WWkJAAJyenRw1BRETaYPlREp2S2ldffQVra2t06NBBvI9jx44dYW1tja+++goAYGlpiY8//livwRIRET2OTuVHtVqNqKgoXLx4EZcu3X+WkouLC1xcXMQ+PXr00E+ERERk8DMsfXmqi6+bNWsGhUKB5s2bw8hIL9dxExFRZbikXxKdyo8FBQXw9fWFubk5WrVqheTk+w8mnDJliqTnqRERET0LOiW1kJAQnD59GjExMTA1NRXbPTw8sG3bNr0FR0RE/8OFIpLoVDPcs2cPtm3bhs6dO0OhUIjtrVq1QlJSkt6CIyKi+wQDT0b6otNM7fbt27CxsXmoPT8/XyPJERERPU86JbWOHTsiMjJS/PlBIvvyyy/h7u6un8iIiOhvLD9KolP5cfHixejTpw/Onz+PsrIyrFy5EufPn8fRo0cRGxv75AGIiEg7vKOIJDrN1Lp164b4+HiUlZXBzc0NP/30E2xsbBAXF4cOHTroO0YiIiJJdL64rHnz5vjiiy/0GQsRET2KgZcN9UWrpFarVq0nLgRRKBSV3uyYiIieApOaJFoltd27dz9yX1xcHFatWoUK1n2JiKiKaJXUBgwY8FBbYmIiZs2ahb1792LkyJFYuHCh3oIjIqL7BIEzNSl0WigCACkpKZg4cSLc3NxQVlaG+Ph4bNiwAY6OjvqMj4iIAC7pl0jrpJaTk4Pg4GA4Ozvj3LlziI6Oxt69e9G6detnER8REZFkWpUfw8LCsHTpUqjVanz77beVliOJiOgZMPAZlr5oNVObNWsWioqK4OzsjA0bNmDQoEGVbkREpF9ChaC3TRtr165FmzZtoFKpoFKp4O7ujv3794v7i4qKEBAQgPr168PS0hKDBw9Genq6xhjJycnw9vaGubk5bGxsMGPGjIdWycfExKB9+/ZQKpVwdnbG+vXrdfo9aTVTGzNmDO/tSERUg9jb22PJkiV44YUXIAgCNmzYgAEDBuDUqVNo1aoVAgMDERkZiR07dsDKygqTJ0/GoEGD8NtvvwEAysvL4e3tDbVajaNHjyI1NRVjxoyBsbExFi9eDAC4evUqvL294efnh4iICERHR2PChAlo1KgRvLy8tIpXIVSTJTWlqReqOgSqIcwcPao6BKohykpu6W2sHJ+eehvLakP0Ux1vbW2NZcuWYciQIWjYsCG2bNmCIUOGAAAuXryIli1bIi4uDp07d8b+/fvRr18/pKSkwNbWFgAQHh6O4OBg3L59GyYmJggODkZkZCTOnj0rvsewYcOQnZ2NAwcOaBWbzqsfiYjoOarQ31ZcXIzc3FyNrbi4+IkhlJeXY+vWrcjPz4e7uztOnDiB0tJSeHj8/Yfiiy++iCZNmiAuLg7A/WuY3dzcxIQGAF5eXsjNzcW5c+fEPv8c40GfB2Nog0mNiKiGCQ0NhZWVlcYWGhr6yP4JCQmwtLSEUqmEn58fdu/eDVdXV6SlpcHExAR169bV6G9ra4u0tDQAQFpamkZCe7D/wb7H9cnNzUVhYaFWn03nez8SEdHzo8+HhIaEhCAoKEijTalUPrK/i4sL4uPjkZOTg507d8LHx6faPpGFSY2ISA70mNSUSuVjk9i/mZiYwNnZGQDQoUMHHD9+HCtXrsTbb7+NkpISZGdna8zW0tPToVarAQBqtRp//PGHxngPVkf+s8+/V0ymp6dDpVLBzMxMq8/G8iMREWmloqICxcXF6NChA4yNjREd/ffCk8TERCQnJ4sPjHZ3d0dCQgIyMjLEPlFRUVCpVHB1dRX7/HOMB310eeg0Z2pERHJQRfeKDwkJQZ8+fdCkSRPcu3cPW7ZsQUxMDA4ePAgrKyv4+voiKCgI1tbWUKlUmDJlCtzd3dG5c2cAgKenJ1xdXTF69GiEhYUhLS0Ns2fPRkBAgDhb9PPzw+rVqzFz5kyMHz8ehw4dwvbt2xEZGal1vExqREQyoM9zatrIyMjAmDFjkJqaCisrK7Rp0wYHDx5Er169AADLly9HrVq1MHjwYBQXF8PLywtr1qwRj69duzb27dsHf39/uLu7w8LCAj4+Pho3v3dyckJkZCQCAwOxcuVK2Nvb48svv9T6GjWA16lRDcTr1Oh50ed1allvvaa3sertiNHbWNUNZ2pERHLAR1VKwqRGRCQDVVV+lBuufiQiIoPBmRoRkRyw/CgJkxoRkQwITGqSsPxIREQGgzM1IiI54ExNEiY1IiIZYPlRGpYfiYjIYHCmRkQkB5ypScKkRkQkAyw/SsPyIxERGQzO1IiIZIAzNWmY1IiIZIBJTRqWH4mIyGBwpkZEJAeCoqojkAUmNSIiGWD5URqWH4mIyGBwpkZEJANCBcuPUjCpERHJAMuP0rD8SEREBoMzNSIiGRC4+lESJjUiIhlg+VEalh+JiMhgcKZGRCQDXP0oDZMaEZEMCEJVRyAPLD8SEZHB4EyNiEgGWH6UhkmNiEgGmNSkYfmRiIgMBmdqREQywIUi0jCpERHJAMuP0rD8SEREBoMzNSIiGeC9H6VhUiMikgHe+1Ealh+JiMhgcKZGRCQDFSw/SsKkRkQkAzynJg3Lj0REZDA4UyMikgFepyYNkxoRkQzwjiLSsPxIREQGgzM1IiIZYPlRGiY1IiIZ4JJ+aVh+JCIig8GZGhGRDPA6NWmY1IiIZICrH6Vh+ZGIiAwGZ2pERDLAhSLSMKkREckAz6lJw/IjERE9UmhoKF5++WXUqVMHNjY2GDhwIBITEzX6vPbaa1AoFBqbn5+fRp/k5GR4e3vD3NwcNjY2mDFjBsrKyjT6xMTEoH379lAqlXB2dsb69eu1jpdJjYhIBgRBf5s2YmNjERAQgN9//x1RUVEoLS2Fp6cn8vPzNfpNnDgRqamp4hYWFibuKy8vh7e3N0pKSnD06FFs2LAB69evx9y5c8U+V69ehbe3N3r06IH4+HhMmzYNEyZMwMGDB7WKVyEI1WNNTWnqhaoOgWoIM0ePqg6Baoiyklt6G+tP+4F6G6vjzT06H3v79m3Y2NggNjYW3bt3B3B/ptauXTusWLGi0mP279+Pfv36ISUlBba2tgCA8PBwBAcH4/bt2zAxMUFwcDAiIyNx9uxZ8bhhw4YhOzsbBw4ckBwfZ2pERDVMcXExcnNzNbbi4mJJx+bk5AAArK2tNdojIiLQoEEDtG7dGiEhISgoKBD3xcXFwc3NTUxoAODl5YXc3FycO3dO7OPhofkHp5eXF+Li4rT6bNVmoYilk2dVh0A1RGHKr1UdApHW9LlQJDQ0FAsWLNBomzdvHubPn//Y4yoqKjBt2jR07doVrVu3FttHjBgBR0dH2NnZ4cyZMwgODkZiYiK+++47AEBaWppGQgMg/pyWlvbYPrm5uSgsLISZmZmkz1ZtkhoRET2aPpf0h4SEICgoSKNNqVQ+8biAgACcPXsWR44c0WifNGmS+NrNzQ2NGjVCz549kZSUhObNm+snaIlYfiQiqmGUSiVUKpXG9qSkNnnyZOzbtw+HDx+Gvb39Y/t26tQJAHDlyhUAgFqtRnp6ukafBz+r1erH9lGpVJJnaQCTGhGRLAh63LR6X0HA5MmTsXv3bhw6dAhOTk5PPCY+Ph4A0KhRIwCAu7s7EhISkJGRIfaJioqCSqWCq6ur2Cc6OlpjnKioKLi7u2sVL8uPREQyUFV3FAkICMCWLVvw/fffo06dOuI5MCsrK5iZmSEpKQlbtmxB3759Ub9+fZw5cwaBgYHo3r072rRpAwDw9PSEq6srRo8ejbCwMKSlpWH27NkICAgQZ4h+fn5YvXo1Zs6cifHjx+PQoUPYvn07IiMjtYq32izpV5o6VHUIVEPk3Yyt6hCohjBu0ExvYx1tNFhvY3VJ3SW5r0JReTL95ptvMHbsWNy4cQOjRo3C2bNnkZ+fDwcHB7z55puYPXs2VCqV2P/69evw9/dHTEwMLCws4OPjgyVLlsDI6O+5VUxMDAIDA3H+/HnY29tjzpw5GDt2rFafjUmNahwmNXpe9JnUflMP0dtYXdN26m2s6oblRyIiGaio6gBkggtFiIjIYHCmRkQkAwJ4l34pmNSIiGSgolqsfqj+WH4kIiKDwZkaEZEMVLD8KAmTGhGRDPCcmjQsPxIRkcHgTI2ISAZ4nZo0TGpERDLA8qM0LD8SEZHB4EyNiEgGWH6UhkmNiEgGmNSkYfmRiIgMBmdqREQywIUi0jCpERHJQAVzmiQsPxIRkcHgTI2ISAZ470dpmNSIiGSAT56RhuVHIiIyGJypERHJAK9Tk4ZJjYhIBioUPKcmBcuPRERkMDhTIyKSAS4UkYZJjYhIBnhOTRqWH4mIyGBwpkZEJAO8TZY0TGpERDLAO4pIw/IjEREZDM7UiIhkgKsfpWFSIyKSAZ5Tk4blRyIiMhicqRERyQCvU5OGSY2ISAZ4Tk0alh+JiMhgcKZGRCQDXCgiDZMaEZEM8JyaNCw/EhGRweBMjYhIBjhTk4ZJjYhIBgSeU5OE5UciIjIYnKkREckAy4/SMKkREckAk5o0LD8SEZHB4EyNiEgGeJssaZjUiIhkgHcUkYblRyIiMhicqRERyQAXikjDpEZEJANMatKw/EhERAaDSY2ISAYEPW7aCA0Nxcsvv4w6derAxsYGAwcORGJiokafoqIiBAQEoH79+rC0tMTgwYORnp6u0Sc5ORne3t4wNzeHjY0NZsyYgbKyMo0+MTExaN++PZRKJZydnbF+/Xoto2VSIyKShQqF/jZtxMbGIiAgAL///juioqJQWloKT09P5Ofni30CAwOxd+9e7NixA7GxsUhJScGgQYPE/eXl5fD29kZJSQmOHj2KDRs2YP369Zg7d67Y5+rVq/D29kaPHj0QHx+PadOmYcKECTh48KBW8SoEQagWlz8oTR2qOgSqIfJuxlZ1CFRDGDdoprexwhxH6W2sdy99heLiYo02pVIJpVL5xGNv374NGxsbxMbGonv37sjJyUHDhg2xZcsWDBkyBABw8eJFtGzZEnFxcejcuTP279+Pfv36ISUlBba2tgCA8PBwBAcH4/bt2zAxMUFwcDAiIyNx9uxZ8b2GDRuG7OxsHDhwQPJn40yNiEgGKvS4hYaGwsrKSmMLDQ2VFEdOTg4AwNraGgBw4sQJlJaWwsPDQ+zz4osvokmTJoiLiwMAxMXFwc3NTUxoAODl5YXc3FycO3dO7PPPMR70eTCGVFz9SEQkA/osqYWEhCAoKEijTcosraKiAtOmTUPXrl3RunVrAEBaWhpMTExQt25djb62trZIS0sT+/wzoT3Y/2Df4/rk5uaisLAQZmZmkj4bkxoRUQ0jtdT4bwEBATh79iyOHDnyDKLSD5YfiYhkoAKC3jZdTJ48Gfv27cPhw4dhb28vtqvVapSUlCA7O1ujf3p6OtRqtdjn36shH/z8pD4qlUryLA1gUiMikgV9nlPThiAImDx5Mnbv3o1Dhw7ByclJY3+HDh1gbGyM6OhosS0xMRHJyclwd3cHALi7uyMhIQEZGRlin6ioKKhUKri6uop9/jnGgz4PxpCK5UciInqkgIAAbNmyBd9//z3q1KkjngOzsrKCmZkZrKys4Ovri6CgIFhbW0OlUmHKlClwd3dH586dAQCenp5wdXXF6NGjERYWhrS0NMyePRsBAQFiGdTPzw+rV6/GzJkzMX78eBw6dAjbt29HZGSkVvFyST/VOFzST8+LPpf0L3Qcqbex5l6PkNxXoaj8wrZvvvkGY8eOBXD/4uv33nsP3377LYqLi+Hl5YU1a9aIpUUAuH79Ovz9/RETEwMLCwv4+PhgyZIlMDL6e24VExODwMBAnD9/Hvb29pgzZ474HpLjZVKjmoZJjZ4XfSa1+XpMavO1SGpyw3NqRERkMHhOjYhIBviQUGmY1IiIZEDXpfg1DcuPRERkMDhTIyKSAc7TpGFSIyKSAT75Whqdy4+//vorRo0aBXd3d9y6dQsAsGnTpmp9TzAiIjJsOiW1Xbt2wcvLC2ZmZjh16pT4XJ6cnBwsXrxYrwESEVHV3/tRLnRKaosWLUJ4eDi++OILGBsbi+1du3bFyZMn9RYcERHdJ+hxM2Q6JbXExER07979oXYrK6uH7tRMRET0vOiU1NRqNa5cufJQ+5EjR9Csmf5uC0NERPdV1V365UanpDZx4kS8++67OHbsGBQKBVJSUhAREYHp06fD399f3zESEdV4PKcmjU5L+mfNmoWKigr07NkTBQUF6N69O5RKJaZPn44pU6boO0YiIiJJnuou/SUlJbhy5Qry8vLg6uoKS0tLnQPhXfrpeeFd+ul50edd+gObDtPbWMuvbdXbWNWNTjO1zZs3Y9CgQTA3NxefWkpERM+OoZ8L0xedzqkFBgbCxsYGI0aMwI8//ojy8nJ9x0VERKQ1nZJaamoqtm7dCoVCgaFDh6JRo0YICAjA0aNH9R0fEREBEPT4nyHTKakZGRmhX79+iIiIQEZGBpYvX45r166hR48eaN68ub5jJCIikuSpb2hsbm4OLy8vZGVl4fr167hw4YI+4iIion/gOTVpdE5qBQUF2L17NyIiIhAdHQ0HBwcMHz4cO3fu1Gd8REQEPiRUKp2S2rBhw7Bv3z6Ym5tj6NChmDNnDtzd3fUdGxERkVZ0Smq1a9fG9u3b4eXlhdq1a+s7JiIi+hfO06TRKalFREToOw4iInoMlh+lkbz6cdWqVSgqKhJfP26rqSwtLfDRsnm4dCkO2VmXEXN4Nzp0aPvYY0xMTLBgwUxcuhSH3JwrSEw8Ch+ft59pnN27d8bvcT8iN+cKzp/7FaNHv6Wxf8aMAPx2ZB/u3L6AG8mnsGP7l2jxAm9UXV19uWk7WnftgyUrwh/Z58pf1zHtv4vgOdgHrbv2waZtu59LbAcP/Yr+wyeifY838OZof/xy9A+N/Z99tRn9h0/Eyz0HokvvtzDh3RCcOXfxucRGhknyTG358uUYOXIkTE1NsXz58kf2UygUmDp1ql6Ck5vwtcvQqlULjB8/Dakp6Rg+4k3s/3EL2r3UEykpaZUesyViLWxsGsDPbwaSkq5BrbZBrVo6P5Acjo72uJQY98jbjjVt6oA9uzfgiy82Y+zYqejRoyvC14YhLTUDUT/fv31U91c6I3zdBvz552kYGdXGBwuDsS8yAu3avY6CgkKdYyP9S7iQiB3f/4gWzk6P7VdYXAR7OzU8X++GsFWf6+W9/zh5BrM//Bg/7dpQ6f5TCecxc/4SvPvOOLza9f/w408xmBryAXZ88yleaNYUANDUoTH+G/Qf2NupUVxcgo3bdmNS4Pv4cdtXsK5XVy9xGgqufpRGclK7evVqpa/pPlNTU7z5Zh8MGeKLI0eOAQAWLVoO774emDRpNObPX/bQMZ69XsMrr3TCiy27ISsrGwBw/frNh/qNGzcM096dhKZNHXD9+k189tk3WPf5Rp3inDhhFK5du4HgWR8AAC4mXkGXLv+HqVMniEmt/xujNY6ZMDEIt26eRvv2bcTPRlWvoKAQsxYsw/zgd7Fuw7eP7evW0gVuLV0AACvWflNpn4qKCny1eQd2/rAfd+5mwbFJY/iNHQ7PHq/oFN/m7d+ja6eOGD9yCABgyqQxiDt+Elt27sW8mfdvfO7t2UPjmJlTJ+K7fQdxKekqOnd8Saf3NVSGftG0vug0JVi4cCEKCgoeai8sLMTChQufOig5MjKqDSMjIxQVF2u0FxYVoUuXlys9pl+/Xjh58gzeC/LDX0nHcTYhFktCZ8PU1FTsM2zYQMydMx1z54WhbbvXMWfuUsybNx2jRg3RKc5OnTvg0KFfNdqifo5Fp07tH3mMlUoFAMjMzNbpPenZWPTxZ+ju/jLcX9bPP/5fbNqGHw5EY+6MKdizORxjhr6JWQuX4fipMzqNd/rcBbh3bKfR1qVTB5w+V/m1rKWlpdjx/X7UsbSAizPL3aQbnRaKLFiwAH5+fjA3N9doLygowIIFCzB37tzHHl9cXIzif/3jLwgCFAqFLuFUC3l5+YiL+xMhIe/i4sUrSE+/jbffHoDOnTogKelapcc4OTVBly4vo6ioGEPfnogG9eth5aoPYV2/HiZNeg8AMHfOewie9QG+//4AAODatRto2bIFJviOxObN2l8TqLZtiPSMOxptGem3YWWlgqmpqXje9AGFQoGPPpqH347+gfPnE7V+P3o2fvw5BhcuJWHrlyv1Ml5JSQm+3LgNX6wMRbvWLQEADo0b4eSZc9jx/X68/FIbrce8czcL9a3rabQ1sK6HO3ezNNpifjuGGfOWoKioGA3rW+PzFR+iXl0r3T+MgWL5URqdktqjEtDp06dhbW39xONDQ0OxYMECjbZatevAyEjeX+TxvtOwbt1HuHb1T5SVleHUqbPYtv17tH/JrdL+tWrVgiAAPmOnIjf3HgBg5syF2PrtOkyd+j5q1VKgefOmWBe+DGvXLBWPMzKqjZyce+LPp07+jCZN7AFA/P/L3Tt/n2z/7bc/8MaAMTp9plUrP4RrKxe8/vognY4n/UtNv40lK9bhixWLoVSa6GXM5JupKCwqxsRp/9VoLy0tQ8sWf9/67mWPN8XXFeUVKCkt1Wjr5/m6WFqU6v/at8Wu9Z8hKzsHO/cewPQ5odjyxQrU5zk1DSw/SqNVUqtXrx4UCgUUCgVatGihkdjKy8uRl5cHPz+/J44TEhKCoKAgjbYGDeX/CJu//rqOXr3egrm5GVSqOkhLy8DmTWtw9Wpypf1T09KRkpImJjQASLx4BbVq1YJ9YzVy7+UBAPz/MxPH/4jXOLa84u8nIwwY6ANjI2MAgF1jNX6O2oH/+7/e4v7Cf8y+0tJvw9amgcZYNrYNkZOT+9AsbcXyD9Cnb094eAzBrVuVL3Sh5+984mVkZmVj6PjJYlt5eQVOxJ/Ft9/txcnDP2h9/WhB4f0FQGuWLYBtQ83vh7Gxsfh61/rPxNdnzl3E8rVf45vVYWKbhcXf1ZsG9evhbqbmrOxOZhYa1NecvZmbmaKJvR2a2NuhbeuW6Pu2L77bexATxzzbVcBkmLRKaitWrIAgCBg/fjwWLFgAK6u/Z1YmJiZo2rSppDuLKJVKKJVKjTY5lx7/raCgEAUFhahb1wq9enXHf99fXGm/uLg/MXhQP1hYmCM///45yhdeaIby8nLcvJWGoqIi3LqVBicnR2zduueR75ecfEt8XVZeBgBI+utapX2P/X4CvXu/rtHWs+crOHbspEbbiuUf4I03esPT8y1cu3bjSR+ZnqPOHdph96a1Gm2zP/wETo4O8B31lk43RGjetAlMTIyRmn77saXGJvZ24uu0jDuoXbu2Rts/tW3VEr+fiMfot/+eycUdP4W2rVo+NpaKivszQNLE8qM0WiU1Hx8fAICTkxO6dOmi8RccAb08XoVCocCly0lo3rwpQhe/j8TEJGzYsB0A8MEHwbCzU8PXNxAAsHXrHoSEvIsvPv8YCz/4BA0aWCM09H2s37BNnDV9sOhjfPLxQuTm5OKnn2JgolSiQ4c2qFfXCitXfaF1jF98uRn+/mOx+MP/YsOGbXjtta4YMrgfBg4cK/ZZtfJDvP32AAx5awLu5eXD1rYhACAn595Dszl6/iwszMUl8Q+YmZmirqqO2B7ywUewaVAfgf7jANxfhJH0v4pBaWkZ0m/fxcVLSTA3N0MTeztYWJhj7PDBCFv1OYSKCrzUphXy8gtw6sw5WFqYY0DfXlrHOWroAIwLmIn13+5C9y7/h/0/x+LcxcuYH3z/kp+CwiJ8vmErenTrhIYNrJGVnYtvv9uLjDt34aXjiktDViGw/CiF5KSWm5sL1f9Wwb300ksoLCxEYWHl1yw96FfTqKzqYNEHs9C4sRqZmdnYs2c/5s4LQ1nZ/dmTWm0LB4fGYv/8/AJ49x2B5csXIu5oJO5mZmHXzn2Y94/l/998sxUFBUUICnwHoaHvIz+/EGfPXcSnn36lU4zXrt3AwDd9sCxsHiZPHo9bt9Lg5z9TXM4PAO+8c//8289ROzSOnTAxCJs2abZR9ZSanoFa/6h+ZNzJxJBxf5cr13+7C+u/3YWOL7lh/f/Kh1MmjkG9ulb4ctN23EhJg8rSAi1dnHUuA77k5oql84Px6ecbsHLdejjaN8aq0Dli4q1dqxauXr+BH/b/jKycHNRVqdC6ZQtsWLMMzs0cdf/wVKMpBEFa+q9duzZSU1NhY3P/4uDKyoUPFpDo8iTsR10sTKRveTdjn9yJSA+MG+jv0oRRjvpbrLX5+nd6G6u6kTxTO3TokLiy8fDhw88sICIiehjv/SiN5KT26quvVvqaiIioutDpjiIHDhzAkSNHxJ8/++wztGvXDiNGjEBWVtZjjiQiIl0IevzPkOmU1GbMmIHc3FwAQEJCAoKCgtC3b19cvXr1oevPiIjo6VXocTNkOt1R5OrVq3B1vX+x9K5du9C/f38sXrwYJ0+eRN++ffUaIBERkVQ6zdRMTEzEGxr//PPP8PT0BABYW1uLMzgiItKfCgh62wyZTjO1bt26ISgoCF27dsUff/yBbdu2AQAuXboEe3t7vQZIRES896NUOs3UVq9eDSMjI+zcuRNr165F48b3Lyjev38/evfu/YSjiYiIng3JF18/a7z4mp4XXnxNz4s+L74e5PiG3sb67voPehurutGp/Ajcvyv/nj17cOHC/Qf+tWrVCm+88YZON1MlIqLHqybzj2pPp6R25coV9O3bF7du3YKLy/1HxIeGhsLBwQGRkZFo3rz5E0YgIiLSP53OqU2dOhXNmzfHjRs3cPLkSZw8eRLJyclwcnLC1KlT9R0jEVGNx9WP0ug0U4uNjcXvv/+u8ZTr+vXrY8mSJejatavegiMiovsM/aJpfdFppqZUKnHv3r2H2vPy8mBiop/HyxMREWlLp6TWr18/TJo0CceOHYMgCBAEAb///jv8/Pzwxhv6W6FDRET38d6P0uiU1FatWgVnZ2d06dIFpqamMDU1RdeuXeHs7IyVK1fqO0YiohqvKs+p/fLLL+jfvz/s7OygUCiwZ88ejf1jx46FQqHQ2P59zXJmZiZGjhwJlUqFunXrwtfXF3l5eRp9zpw5g1deeQWmpqZwcHBAWFiY1rFqdU6toqICy5Ytww8//ICSkhIMHDgQPj4+UCgUaNmyJZydnbUOgIiIqrf8/Hy0bdsW48ePx6BBlT+stHfv3vjmm2/En5VKpcb+kSNHIjU1FVFRUSgtLcW4ceMwadIkbNmyBQCQm5sLT09PeHh4IDw8HAkJCRg/fjzq1q2LSZMmSY5Vq6T24YcfYv78+fDw8ICZmRl+/PFHWFlZ4euvv9ZmGCIi0lJVXqfWp08f9OnT57F9lEol1Gp1pfsuXLiAAwcO4Pjx4+jYsSMA4NNPP0Xfvn3x0Ucfwc7ODhERESgpKcHXX38NExMTtGrVCvHx8fjkk0+0SmpalR83btyINWvW4ODBg9izZw/27t2LiIgIVFRwXQ4R0bOkz0fPFBcXIzc3V2MrLi5+qvhiYmJgY2MDFxcX+Pv74+7du+K+uLg41K1bV0xoAODh4YFatWrh2LFjYp/u3btrLDb08vJCYmKiVs/p1CqpJScnazxaxsPDAwqFAikpKdoMQ0REVSg0NBRWVlYaW2hoqM7j9e7dGxs3bkR0dDSWLl2K2NhY9OnTB+Xl5QCAtLQ02NjYaBxjZGQEa2trpKWliX1sbW01+jz4+UEfKbQqP5aVlcHU1FSjzdjYGKWlpdoMQ0REWtLnqsWQkJCHHuj873Ng2hg2bJj42s3NDW3atEHz5s0RExODnj176jyuLrRKaoIgYOzYsRofvqioCH5+frCwsBDbvvvuO/1FSEREer0TiFKpfKok9iTNmjVDgwYNcOXKFfTs2RNqtRoZGRkafcrKypCZmSmeh1Or1UhPT9fo8+DnR52rq4xWSc3Hx+ehtlGjRmkzBBERGbibN2/i7t27aNSoEQDA3d0d2dnZOHHiBDp06AAAOHToECoqKtCpUyexz/vvv4/S0lIYGxsDAKKiouDi4oJ69epJfm8+eoZqHD56hp4XfT56pqe9p97Gir75k1b98/LycOXKFQDASy+9hE8++QQ9evSAtbU1rK2tsWDBAgwePBhqtRpJSUmYOXMm7t27h4SEBHFG2KdPH6SnpyM8PFxc0t+xY0dxSX9OTg5cXFzg6emJ4OBgnD17FuPHj8fy5cu1Wv3IpEY1DpMaPS/6TGo97HvpbazDN6O06h8TE4MePXo81O7j44O1a9di4MCBOHXqFLKzs2FnZwdPT0988MEHGgs/MjMzMXnyZOzduxe1atXC4MGDsWrVKlhaWop9zpw5g4CAABw/fhwNGjTAlClTEBwcrFWsTGpU4zCp0fNiKElNTnR+SCgRET0/hn7PRn1hUiMikoGK6lFUq/Z0uqExERFRdcSZGhGRDHCeJg2TGhGRDOjz4mtDxvIjEREZDM7UiIhkgDM1aZjUiIhkoJpcUlztsfxIREQGgzM1IiIZYPlRGiY1IiIZ4B1FpGH5kYiIDAZnakREMsCFItIwqRERyQDPqUnD8iMRERkMztSIiGSA5UdpmNSIiGSA5UdpWH4kIiKDwZkaEZEM8Do1aZjUiIhkgE++loblRyIiMhicqRERyQDLj9IwqRERyQDLj9Kw/EhERAaDMzUiIhlg+VEaJjUiIhlg+VEalh+JiMhgcKZGRCQDLD9Kw6RGRCQDLD9Kw/IjEREZDM7UiIhkgOVHaZjUiIhkQBAqqjoEWWD5kYiIDAZnakREMsCHhErDpEZEJAMCVz9KwvIjEREZDM7UiIhkgOVHaZjUiIhkgOVHaVh+JCIig8GZGhGRDPA2WdIwqRERyQDvKCINy49ERGQwOFMjIpIBLhSRhkmNiEgGuKRfGpYfiYjIYHCmRkQkAyw/SsOkRkQkA1zSLw3Lj0REZDA4UyMikgGWH6VhUiMikgGufpSG5UciInqsX375Bf3794ednR0UCgX27NmjsV8QBMydOxeNGjWCmZkZPDw8cPnyZY0+mZmZGDlyJFQqFerWrQtfX1/k5eVp9Dlz5gxeeeUVmJqawsHBAWFhYVrHyqRGRCQDgiDobdNWfn4+2rZti88++6zS/WFhYVi1ahXCw8Nx7NgxWFhYwMvLC0VFRWKfkSNH4ty5c4iKisK+ffvwyy+/YNKkSeL+3NxceHp6wtHRESdOnMCyZcswf/58fP7551rFqhCqSaFWaepQ1SFQDZF3M7aqQ6AawrhBM72NZWnupLex7mZdRHFxsUabUqmEUql84rEKhQK7d+/GwIEDAdxPtnZ2dnjvvfcwffp0AEBOTg5sbW2xfv16DBs2DBcuXICrqyuOHz+Ojh07AgAOHDiAvn374ubNm7Czs8PatWvx/vvvIy0tDSYmJgCAWbNmYc+ePbh48aLkz8aZGhFRDRMaGgorKyuNLTQ0VKexrl69irS0NHh4eIhtVlZW6NSpE+Li4gAAcXFxqFu3rpjQAMDDwwO1atXCsWPHxD7du3cXExoAeHl5ITExEVlZWZLj4UIRIiIZ0Odd+kNCQhAUFKTRJmWWVpm0tDQAgK2trUa7ra2tuC8tLQ02NjYa+42MjGBtba3Rx8nJ6aExHuyrV6+epHiY1IiIZECfF19LLTXKEcuPRESkM7VaDQBIT0/XaE9PTxf3qdVqZGRkaOwvKytDZmamRp/Kxvjne0jBpEZEJANVufrxcZycnKBWqxEdHS225ebm4tixY3B3dwcAuLu7Izs7GydOnBD7HDp0CBUVFejUqZPY55dffkFpaanYJyoqCi4uLpJLjwCTGhGRLAh6/E9beXl5iI+PR3x8PID7i0Pi4+ORnJwMhUKBadOmYdGiRfjhhx+QkJCAMWPGwM7OTlwh2bJlS/Tu3RsTJ07EH3/8gd9++w2TJ0/GsGHDYGdnBwAYMWIETExM4Ovri3PnzmHbtm1YuXLlQ+f+noRL+qnG4ZJ+el70uaRfn/9GFhfd0Kp/TEwMevTo8VC7j48P1q9fD0EQMG/ePHz++efIzs5Gt27dsGbNGrRo0ULsm5mZicmTJ2Pv3r2oVasWBg8ejFWrVsHS0lLsc+bMGQQEBOD48eNo0KABpkyZguDgYK1iZVKjGodJjZ4XfSY1E6W93sYqKb6pt7GqG65+JCKSgWoy/6j2eE6NiIgMBmdqREQywHmaNNXmnBppp7i4GKGhoQgJCTHYiyipeuB3jeSESU2mcnNzYWVlhZycHKhUqqoOhwwYv2skJzynRkREBoNJjYiIDAaTGhERGQwmNZlSKpWYN28eT9zTM8fvGskJF4oQEZHB4EyNiIgMBpMaEREZDCY1IiIyGExqRERkMJjUaoimTZtixYoVVR0GyUhMTAwUCgWys7Mf24/fLapOmNT0YOzYsVAoFFiyZIlG+549e6BQKJ5rLOvXr0fdunUfaj9+/DgmTZr0XGOh5+PB90+hUMDExATOzs5YuHAhysrKnmrcLl26IDU1FVZWVgD43SJ5YFLTE1NTUyxduhRZWVlVHUqlGjZsCHNz86oOg56R3r17IzU1FZcvX8Z7772H+fPnY9myZU81pomJCdRq9RP/MON3i6oTJjU98fDwgFqtRmho6CP7HDlyBK+88grMzMzg4OCAqVOnIj8/X9yfmpoKb29vmJmZwcnJCVu2bHmotPPJJ5/Azc0NFhYWcHBwwH/+8x/k5eUBuF8uGjduHHJycsS/3OfPnw9As0Q0YsQIvP322xqxlZaWokGDBti4cSMAoKKiAqGhoXBycoKZmRnatm2LnTt36uE3Rc+CUqmEWq2Go6Mj/P394eHhgR9++AFZWVkYM2YM6tWrB3Nzc/Tp0weXL18Wj7t+/Tr69++PevXqwcLCAq1atcKPP/4IQLP8yO8WyQWTmp7Url0bixcvxqeffoqbNx9+VHpSUhJ69+6NwYMH48yZM9i2bRuOHDmCyZMni33GjBmDlJQUxMTEYNeuXfj888+RkZGhMU6tWrWwatUqnDt3Dhs2bMChQ4cwc+ZMAPfLRStWrIBKpUJqaipSU1Mxffr0h2IZOXIk9u7dKyZDADh48CAKCgrw5ptvAgBCQ0OxceNGhIeH49y5cwgMDMSoUaMQGxurl98XPVtmZmYoKSnB2LFj8eeff+KHH35AXFwcBEFA3759UVpaCgAICAhAcXExfvnlFyQkJGDp0qWwtLR8aDx+t0g2BHpqPj4+woABAwRBEITOnTsL48ePFwRBEHbv3i08+BX7+voKkyZN0jju119/FWrVqiUUFhYKFy5cEAAIx48fF/dfvnxZACAsX778ke+9Y8cOoX79+uLP33zzjWBlZfVQP0dHR3Gc0tJSoUGDBsLGjRvF/cOHDxfefvttQRAEoaioSDA3NxeOHj2qMYavr68wfPjwx/8y6Ln75/evoqJCiIqKEpRKpTBw4EABgPDbb7+Jfe/cuSOYmZkJ27dvFwRBENzc3IT58+dXOu7hw4cFAEJWVpYgCPxukTzwydd6tnTpUrz++usP/RV7+vRpnDlzBhEREWKbIAioqKjA1atXcenSJRgZGaF9+/bifmdnZ9SrV09jnJ9//hmhoaG4ePEicnNzUVZWhqKiIhQUFEg+r2FkZIShQ4ciIiICo0ePRn5+Pr7//nts3boVAHDlyhUUFBSgV69eGseVlJTgpZde0ur3Qc/Hvn37YGlpidLSUlRUVGDEiBEYNGgQ9u3bh06dOon96tevDxcXF1y4cAEAMHXqVPj7++Onn36Ch4cHBg8ejDZt2ugcB79bVNWY1PSse/fu8PLyQkhICMaOHSu25+Xl4Z133sHUqVMfOqZJkya4dOnSE8e+du0a+vXrB39/f3z44YewtrbGkSNH4Ovri5KSEq1O1o8cORKvvvoqMjIyEBUVBTMzM/Tu3VuMFQAiIyPRuHFjjeN4U9vqqUePHli7di1MTExgZ2cHIyMj/PDDD088bsKECfDy8kJkZCR++uknhIaG4uOPP8aUKVN0joXfLapKTGrPwJIlS9CuXTu4uLiIbe3bt8f58+fh7Oxc6TEuLi4oKyvDqVOn0KFDBwD3/6r952rKEydOoKKiAh9//DFq1bp/OnT79u0a45iYmKC8vPyJMXbp0gUODg7Ytm0b9u/fj7feegvGxsYAAFdXVyiVSiQnJ+PVV1/V7sNTlbCwsHjou9WyZUuUlZXh2LFj6NKlCwDg7t27SExMhKurq9jPwcEBfn5+8PPzQ0hICL744otKkxq/WyQHTGrPgJubG0aOHIlVq1aJbcHBwejcuTMmT56MCRMmwMLCAufPn0dUVBRWr16NF198ER4eHpg0aRLWrl0LY2NjvPfeezAzMxOXVDs7O6O0tBSffvop+vfvj99++w3h4eEa7920aVPk5eUhOjoabdu2hbm5+SNncCNGjEB4eDguXbqEw4cPi+116tTB9OnTERgYiIqKCnTr1g05OTn47bffoFKp4OPj8wx+a6RvL7zwAgYMGICJEydi3bp1qFOnDmbNmoXGjRtjwIABAIBp06ahT58+aNGiBbKysnD48GG0bNmy0vH43SJZqOqTeobgnyfqH7h69apgYmIi/PNX/Mcffwi9evUSLC0tBQsLC6FNmzbChx9+KO5PSUkR+vTpIyiVSsHR0VHYsmWLYGNjI4SHh4t9PvnkE6FRo0aCmZmZ4OXlJWzcuFHjZL4gCIKfn59Qv359AYAwb948QRA0T+Y/cP78eQGA4OjoKFRUVGjsq6ioEFasWCG4uLgIxsbGQsOGDQUvLy8hNjb26X5ZpHeVff8eyMzMFEaPHi1YWVmJ35lLly6J+ydPniw0b95cUCqVQsOGDYXRo0cLd+7cEQTh4YUigsDvFlV/fJ5aNXbz5k04ODjg559/Rs+ePas6HCKiao9JrRo5dOgQ8vLy4ObmhtTUVMycORO3bt3CpUuXxHMSRET0aDynVo2Ulpbiv//9L/766y/UqVMHXbp0QUREBBMaEZFEnKkREZHB4G2yiIjIYDCpERGRwWBSIyIig8GkRkREBoNJjYiIDAaTGhERGQwmNSIiMhhMakREZDD+HyAcISBy5GikAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "conf_matrix = pd.DataFrame(matrix,index = [\"Negative\",\"Positive\"],columns = [\"Negative\",\"Positive\"])\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(conf_matrix,annot=True,annot_kws={\"size\":10} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGsCAYAAACIIzPWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA440lEQVR4nO3deVxUZdsH8N8MwgCSiCKgPDygkCSlYqgo5lZT5Jat7kK4JbkFWooWpKajlYrbI2VaqfSIppZbpuFSJmmCW4miuZDKqggBOixz3j98m5qHRWY8wDmd3/f9nM9Hb+5zn3t85+nius597qMSBEEAERGRxKjrewJERESVYYAiIiJJYoAiIiJJYoAiIiJJYoAiIiJJYoAiIiJJYoAiIiJJYoAiIiJJalDfE/hTae6l+p4CKYRdi+71PQVSiLKS66KNJeZ/I62dW4k2Vm1iBkVERJIkmQyKiIiqYSiv7xnUOQYoIiI5EAz1PYM6xxIfERFJEjMoIiI5MDCDIiIiCRIEg2iHJVauXAkvLy/Y2toiMDAQx44dq7Z/bGwsfH19YWdnBw8PD0RERODu3btmXZMBioiIqpWQkIDIyEjExMQgJSUF7du3R3BwMLKzsyvt/8UXX2DGjBmIiYlBamoq1qxZg4SEBMycOdOs66qk8sJCPgdFdYXPQVFdEfM5qJJrZ0Qby+Zfbc3qHxgYiE6dOmHFihUAAIPBAA8PD0yaNAkzZsyo0H/ixIlITU1FYmKisW3q1Kk4evQoDh8+XOPrMoMiIpIDwSDaodfrUVBQYHLo9fpKL1tSUoLk5GRotVpjm1qthlarRVJSUqXnBAUFITk52VgGvHTpEnbv3o2+ffua9ZEZoIiIFEan08HR0dHk0Ol0lfbNzc1FeXk5XF1dTdpdXV2RmZlZ6TnDhg3DnDlz8MQTT8Da2hre3t7o1auX2SU+BigiIjkwlIt2REVFIT8/3+SIiooSbaoHDx7E/Pnz8Z///AcpKSnYunUrdu3ahblz55o1DpeZExHJgYgP6mo0Gmg0mhr1dXZ2hpWVFbKyskzas7Ky4ObmVuk577zzDkaOHIkxY8YAANq2bYuioiKMGzcOs2bNglpds9yIGRQREVXJxsYGAQEBJgseDAYDEhMT0bVr10rPKS4urhCErKysAADmrMtjBkVEJAf1+KBuZGQkQkND0bFjR3Tu3BmxsbEoKipCWFgYACAkJATu7u7G+1gDBgzA4sWL0aFDBwQGBuLixYt45513MGDAAGOgqgkGKCIiGbD0AVsxDB48GDk5OYiOjkZmZib8/f2xZ88e48KJ9PR0k4zp7bffhkqlwttvv43r16+jWbNmGDBgAObNm2fWdfkcFCkOn4OiuiLmc1D6334SbSyNdxfRxqpNzKCIiORAgXvxMUAREckBX7dBREQkDcygiIjkgG/UJSIiSWKJj4iISBqYQRERyQFX8RERkSSxxEdERCQNzKCIiOSAJT4iIpIiQVDeMnOW+IiISJKYQRERyYECF0kwQBERyYEC70GxxEdERJLEDIqISA5Y4iMiIklS4GaxLPEREZEkMYMiIpIDlviIiEiSuIqPiIhIGphBERHJAUt8REQkSSzxERERSQMzKCIiOVBgBsUARUQkA3zdBhERkUQwgyIikgOW+IiISJIUuMycJT4iIpIkZlBERHLAEh8REUkSS3xERETSwAyKiEgOWOIjIiJJYomPiIhIGphBERHJAUt8REQkSQoMUCzxERGRJDGDIiKSAwUukmCAIiKSA5b4iIiIpIEZFBGRHLDER0REksQSHxERkTQwgyIikgOW+IiISJJY4iMiIpIGZlBERHKgwAyKAYqISA4Eob5nUOdY4iMiovtauXIlvLy8YGtri8DAQBw7dqzKvr169YJKpapw9OvXz6xrMkAREcmBwSDeYaaEhARERkYiJiYGKSkpaN++PYKDg5GdnV1p/61btyIjI8N4/PLLL7CyssIrr7xi1nUZoIiI5KAeA9TixYsxduxYhIWFwc/PD3FxcbC3t8fatWsr7d+kSRO4ubkZj3379sHe3r7uAtQPP/yAESNGoGvXrrh+/ToAYP369Th8+LClQxIRUR3Q6/UoKCgwOfR6faV9S0pKkJycDK1Wa2xTq9XQarVISkqq0fXWrFmDIUOGoGHDhmbN06IAtWXLFgQHB8POzg4nTpwwfrD8/HzMnz/fkiGJiKg6gkG0Q6fTwdHR0eTQ6XSVXjY3Nxfl5eVwdXU1aXd1dUVmZuZ9p33s2DH88ssvGDNmjNkf2aIA9d577yEuLg6rV6+GtbW1sb1bt25ISUmxZEgiIqqOiCW+qKgo5OfnmxxRUVG1Mu01a9agbdu26Ny5s9nnWrTM/Pz58+jRo0eFdkdHR9y+fduSIYmIqI5oNBpoNJoa9XV2doaVlRWysrJM2rOysuDm5lbtuUVFRdi4cSPmzJlj0TwtyqDc3Nxw8eLFCu2HDx9Gq1atLJoIERFVQxDEO8xgY2ODgIAAJCYmGtsMBgMSExPRtWvXas/dvHkz9Ho9RowYYdFHtihAjR07FlOmTMHRo0ehUqlw48YNxMfHY9q0aQgPD7doIkREVI16XMUXGRmJ1atX4/PPP0dqairCw8NRVFSEsLAwAEBISEilJcI1a9bg+eefR9OmTS36yBaV+GbMmAGDwYCnnnoKxcXF6NGjBzQaDaZNm4ZJkyZZNBEiIpKmwYMHIycnB9HR0cjMzIS/vz/27NljXDiRnp4Otdo03zl//jwOHz6MvXv3WnxdlSBYvn9GSUkJLl68iMLCQvj5+cHBwcHiiZTmXrL4XCJz2LXoXt9TIIUoK7ku2lh31kwTbSy70R+KNlZtsiiD2rBhA1588UXY29vDz89P7DkREdH/UuD7oCy6BxUREQEXFxcMGzYMu3fvRnl5udjzIiIihbMoQGVkZGDjxo1QqVQYNGgQmjdvjgkTJuDIkSNiz4+IiAAIBkG0Qy4sClANGjRA//79ER8fj+zsbCxZsgRXrlxB79694e3tLfYciYioHlfx1ZcHfh+Uvb09goODkZeXh6tXryI1NVWMeRERkcJZHKCKi4uxbds2xMfHIzExER4eHhg6dCi+/PJLMedHRESAIhdJWBSghgwZgp07d8Le3h6DBg3CO++8c98niomI6AHI6N6RWCwKUFZWVti0aROCg4NhZWUl9pyIiIgsC1Dx8fFiz4OIiKojo8UNYqlxgFq2bBnGjRsHW1tbLFu2rNq+kydPfuCJERGRstV4q6OWLVvi+PHjaNq0KVq2bFn1gCoVLl0yf9sibnVEdYVbHVFdEXOro+Kl40Uby35KnGhj1aYaZ1CXL1+u9M9ERFQHLN82VbYselB3zpw5KC4urtB+584di19MRURE9HcWBajZs2ejsLCwQntxcTFmz579wJNSqv9u2YFnXgrF472fw9Cxb+DM2fPV9l+fsA39h4xBQO+BeOqFkVi49CPo9SXGn69el4DBoyejs/ZF9Og3BJNnzMHlq9dq+2OQDISPD8XFtJ9QWPAbjhzegU4d/avs6+fXGpsSPsbFtJ9QVnIdkyeNqdBHrVZj9rtv4sL5JPyRfxHnU3/ErJlv1N4HUCIF7iRhUYASBAEqlapC+6lTp9CkSZMHnpQSffPdIby//GOEjxqOzWuXw9enJV6LfBs3825X2n/X3gNYEvcpwkcNx/YvPsacGW9gT+L3WPrRZ8Y+x0+ewdAXB+CLj5fg49j5KC0rw7iIWSi+c7duPhRJ0iuvPIcPP4jB3PcWo1Pgszh1+ix274pHs2aVv1TO3s4Oly+lY+bb85GRkVVpn7fenIDXxoVgyhtv47F2vRA1az6mTQ3HxAmjavOjKItBEO+QCbOWmTs5OUGlUkGlUqF169YmQaq8vByFhYUYP168G3lKsi5hG14e0Acv9HsGABD95iR8f+RnbNu5F2NGDqrQ/+SZVHRo64d+z/QGALg3d0Xfp3vh9Nlzxj4fLX7P5Jx5syLRo/9QnD1/AR3929bipyEpi5gyFp+s+QKfr9sEAHh9wgz07fMUwl4dgvc/WFmh//HkUziefAoAMP+9mZWO2bVLR2zf8S12f3PvteBXr17DkMED0amTf+18CFIEswJUbGwsBEHAqFGjMHv2bDg6Ohp/ZmNjAy8vL+4oYYHS0lKcPX/BJBCp1Wp06eiPU79Uvrehf9s22Ll3P86cPY+2fr74/XoGvk/6GQOCn6zyOoVF9+4bOjZ6SNwPQLJhbW2Nxx9vhwXvrzC2CYKAxP2H0aVLgMXjJv10HGNGD8fDD7fChQuX0K6dH7oFdca0t1jyFw23OqpeaGgogHtLzoOCgmBtbV0rk1KavNsFKC83oGkTJ5P2pk2ccDm98ntG/Z7pjbz8AowMnwYIAsrKyzHo+b4YFzqk0v4GgwELln6EDu388HArL7E/AsmEs3MTNGjQANlZuSbt2dk5eMTX8jcRLHx/BRo1csCvZw6hvLwcVlZWeCd6If77320POmX6k4xKc2KxaCeJnj17Gv989+5dlJSUmPy8UaNG1Z6v1+uh1+tN2tR6PTQajSXTUaRjKaexel0C3p46Ae0e9UX6tRtYsPQjxH36BcaHDavQ/71FK3Hx0hWsWyWPVz2TvLzyygAMHfIiRoRMwNmzaWjf/lEs/nA2bmRkYf36zfU9PZIpixZJFBcXY+LEiXBxcUHDhg3h5ORkctyPTqeDo6OjybFwqTweHKsNTo0bwcpKjZu38kzab97Kg3OTyv89V6xehwHBT+Ll555Fa++W0PbshimvvYpP1m+C4X9W6cxb9B8cOnIMa5cvhJtLs1r7HCR9ubm3UFZWBhdXZ5N2F5dmyMzKsXjchbp38P4HK7Bp03b88ss5xMdvwdJlqzH9rYkPOmX6f4LBINohFxYFqDfffBP79+/HqlWroNFo8Mknn2D27Nlo0aIF1q1bd9/zo6KikJ+fb3JMn6LcxRXW1tbw830YR4+fNLYZDAYcTT6J9o+1qfScu3o91GrTlZRW6nv/7/xzcxBBEDBv0X+Q+P0RrF22AP9q4VY7H4Bko7S0FCkpp/Fk7yeMbSqVCk/2fgI//ZRs8bj29nYw/E8Jqry8HGq1Rf+JocpwFV/N7NixA+vWrUOvXr0QFhaG7t27w8fHB56enoiPj8fw4cOrPV+j0VQo55WW5FbRWxlCBr+AWfMW4dFHHsZjfr7YsOkr3Lmrx/P9ngYARM39EC7OTRERHgYA6NktEOs2bsUjrb3Rzu8RpF+7geWr16Fnt0DjDvPvLVqJ3fsOYtmCaDS0t0PuzVsAAAeHhrBlOVWxlixdjU/XLEFyymn8/PMJTJ40Fg0b2uGzzxMAAJ+uXYobNzIw6+0FAP7/Fyi/1gAAGxtruLdwQ/v2j6KwsAi//XYFALBz1z5EzZiM33+/jl/Pnoe//2N4Y8o4fPb5xnr5jPTPYFGAunXrFlq1agXg3v2mW7fu/YfviSeeQHh4uHizU5A+2p7Iu52PFZ9sQO6tW3jkYW/ELZprLPFlZGVD/bdl/a+FDoVKpcLyj9chO+cmnJwc0atbICaPCzX2Sdi2CwAQNnG6ybXemxlpDHykPJs3b0cz5yZ4N3oa3Nya4dSpX9Gv/whkZ9/7JfHfHi1MysQtWrgi+ee9xr9PnRqOqVPDcejQETz19CsAgClvvI3Z776F5cvmw8WlKW7cyMLqTzZg7ntL6vbD/ZMpcBVfjTeL/bt27dph+fLl6NmzJ7RaLfz9/fHhhx9i2bJleP/993Htmvm7FXCzWKor3CyW6oqYm8UWzam+MmWOhtHyeGWSRQXisLAwnDp178G9GTNmYOXKlbC1tUVERATefPNNUSdIRETKZFGJLyIiwvhnrVaLc+fOITk5GT4+PmjXrp1okyMiov8no9V3YrEoQP0vT09PeHp6ijEUERFVRkar78RiUYCq6o26KpUKtra28PHxQY8ePYyryYiIiMxlUYBasmQJcnJyUFxcbHwwNy8vD/b29nBwcEB2djZatWqFAwcOwMPDQ9QJExEpkgJX8Vm0SGL+/Pno1KkTLly4gJs3b+LmzZtIS0tDYGAgli5divT0dLi5uZncqyIiogegwAd1LVpm7u3tjS1btsDf39+k/cSJE3jppZdw6dIlHDlyBC+99BIyMjJqNCaXmVNd4TJzqiuiLjOf9YpoYzWcJ4/9ES0q8WVkZKCsrKxCe1lZGTIzMwEALVq0wB9//PFgsyMiIgCQ1R56YrGoxNe7d2+89tprOHHihLHtxIkTCA8Px5NP3nsf0ZkzZ9CyZUtxZklEpHQKLPFZFKDWrFmDJk2aICAgwLivXseOHdGkSROsWbMGAODg4IBFixaJOlkiIlIOi0p8bm5u2LdvH86dO4e0tDQAgK+vL3x9fY19evfuLc4MiYhIVpmPWB7oQd1WrVpBpVLB29sbDRqI8swvERFVhsvMa6a4uBijR4+Gvb09Hn30UaSnpwMAJk2ahAULFog6QSIiUiaLAlRUVBROnTqFgwcPwtbW1tiu1WqRkJAg2uSIiOj/KXCRhEV1ua+++goJCQno0qULVH97R9Gjjz6K3377TbTJERHRPYKMAotYLMqgcnJy4OLiUqG9qKjIJGARERFZyqIA1bFjR+zatcv49z+D0ieffIKuXbuKMzMiIvoLS3w1M3/+fPTp0wdnz55FWVkZli5dirNnz+LIkSM4dOiQ2HMkIiLuJFEzTzzxBE6ePImysjK0bdsWe/fuhYuLC5KSkhAQECD2HImISIEsfnjJ29sbq1evFnMuRERUFRmV5sRiVoBSq9X3XQShUqkq3UiWiIgeAANU9bZt21blz5KSkrBs2TIYFFgnJSIi8ZkVoAYOHFih7fz585gxYwZ27NiB4cOHY86cOaJNjoiI7rHg1X2yZ9EiCQC4ceMGxo4di7Zt26KsrAwnT57E559/Dk9PTzHnR0REgCKXmZsdoPLz8zF9+nT4+Pjg119/RWJiInbs2IHHHnusNuZHREQKZVaAev/999GqVSvs3LkT//3vf3HkyBF0787XZxMR1bp6zqBWrlwJLy8v2NraIjAwEMeOHau2/+3btzFhwgQ0b94cGo0GrVu3xu7du826pkowo7CpVqthZ2cHrVYLKyurKvtt3brVrEkAQGnuJbPPIbKEXQv+UkV1o6zkumhj5YdpRRvL8dPvzOqfkJCAkJAQxMXFITAwELGxsdi8eTPOnz9f6bZ3JSUl6NatG1xcXDBz5ky4u7vj6tWraNy4Mdq3b1/j65q1SCIkJIR77RERKczixYsxduxYhIWFAQDi4uKwa9curF27FjNmzKjQf+3atbh16xaOHDkCa2trAICXl5fZ1zUrQH322WdmX4CIiEQg4uIGvV4PvV5v0qbRaKDRaCr0LSkpQXJyMqKiooxtarUaWq0WSUlJlY6/fft2dO3aFRMmTMDXX3+NZs2aYdiwYZg+fXq11bf/ZfEqPiIiqkMG8Q6dTgdHR0eTQ6fTVXrZ3NxclJeXw9XV1aTd1dUVmZmZlZ5z6dIlfPnllygvL8fu3bvxzjvvYNGiRXjvvffM+sh8TzsRkcJERUUhMjLSpK2y7MlSBoMBLi4u+Pjjj2FlZYWAgABcv34dH3zwAWJiYmo8DgMUEZEMiPnCwqrKeZVxdnaGlZUVsrKyTNqzsrLg5uZW6TnNmzeHtbW1STmvTZs2yMzMRElJCWxsbGp0bZb4iIjkoJ6WmdvY2CAgIACJiYl/TcVgQGJiYpXv/+vWrRsuXrxosvVdWloamjdvXuPgBDBAERHRfURGRmL16tX4/PPPkZqaivDwcBQVFRlX9YWEhJgsoggPD8etW7cwZcoUpKWlYdeuXZg/fz4mTJhg1nVZ4iMikoN63Id78ODByMnJQXR0NDIzM+Hv7489e/YYF06kp6dDrf4r3/Hw8MC3336LiIgItGvXDu7u7pgyZQqmT59u1nXNelC3NvFBXaorfFCX6oqYD+rmvdJLtLGcNh8UbazaxBIfERFJEkt8RERyoMBX7TFAERHJgJjLzOWCJT4iIpIkZlBERHLAEh8REUmRoMAAxRIfERFJEjMoIiI5UGAGxQBFRCQDLPERERFJBDMoIiI5UGAGxQBFRCQDLPERERFJBDMoIiIZUGIGxQBFRCQDSgxQLPEREZEkMYMiIpIDQVXfM6hzDFBERDLAEh8REZFEMIMiIpIBwcASHxERSRBLfERERBLBDIqISAYEruIjIiIpYomPiIhIIphBERHJAFfxERGRJAlCfc+g7rHER0REksQMiohIBljiIyIiSVJigGKJj4iIJIkZFBGRDChxkQQDFBGRDLDER0REJBHMoIiIZIB78RERkSRxLz4iIiKJYAZFRCQDBpb4iIhIipR4D4olPiIikiRmUEREMqDE56AYoIiIZECJO0mwxEdERJLEDIqISAZY4iMiIklS4jJzlviIiEiSmEEREcmAEp+DYoAiIpIBruIjIiKSCGZQREQywEUSREQkSYKgEu2wxMqVK+Hl5QVbW1sEBgbi2LFjVfb97LPPoFKpTA5bW1uzr8kARURE1UpISEBkZCRiYmKQkpKC9u3bIzg4GNnZ2VWe06hRI2RkZBiPq1evmn1dBigiIhkQBPEOcy1evBhjx45FWFgY/Pz8EBcXB3t7e6xdu7bKc1QqFdzc3IyHq6ur2ddlgCIikgGDoBLt0Ov1KCgoMDn0en2l1y0pKUFycjK0Wq2xTa1WQ6vVIikpqcr5FhYWwtPTEx4eHhg4cCB+/fVXsz8zAxQRkcLodDo4OjqaHDqdrtK+ubm5KC8vr5ABubq6IjMzs9JzfH19sXbtWnz99dfYsGEDDAYDgoKCcO3aNbPmKZlVfI08etf3FEgh7vy+v76nQGQ2MR/UjYqKQmRkpEmbRqMRbfyuXbuia9euxr8HBQWhTZs2+OijjzB37twajyOZAEVERFUTc5m5RqOpcUBydnaGlZUVsrKyTNqzsrLg5uZWozGsra3RoUMHXLx40ax5ssRHRERVsrGxQUBAABITE41tBoMBiYmJJllSdcrLy3HmzBk0b97crGszgyIikoH63OkoMjISoaGh6NixIzp37ozY2FgUFRUhLCwMABASEgJ3d3fjfaw5c+agS5cu8PHxwe3bt/HBBx/g6tWrGDNmjFnXZYAiIpKB+txJYvDgwcjJyUF0dDQyMzPh7++PPXv2GBdOpKenQ63+qyCXl5eHsWPHIjMzE05OTggICMCRI0fg5+dn1nVVgiCNLQjt7DzrewqkEAVX9tb3FEghrF19RRvrSPOXRBsrKGOLaGPVJmZQREQywNdtEBGRJBnqewL1gKv4iIhIkphBERHJgACW+IiISIIMkljOVrdY4iMiIkliBkVEJAMGlviIiEiKlHgPiiU+IiKSJGZQREQyoMTnoBigiIhkgCU+IiIiiWAGRUQkAyzxERGRJCkxQLHER0REksQMiohIBpS4SIIBiohIBgzKi08s8RERkTQxgyIikgHuxUdERJKkwLdtsMRHRETSxAyKiEgGlPgcFAMUEZEMGFTKuwfFEh8REUkSMygiIhlQ4iIJBigiIhlQ4j0olviIiEiSmEEREcmAErc6YoAiIpIBJe4kwRIfERFJEjMoIiIZ4Co+IiKSJCXeg2KJj4iIJIkZFBGRDCjxOSgGKCIiGVDiPSiW+IiISJKYQRERyYASF0kwQBERyYAS70GxxEdERJLEDIqISAaUmEExQBERyYCgwHtQLPEREZEkMYMiIpIBlviIiEiSlBigWOIjIiJJYgZFRCQDStzqiAGKiEgGlLiTBEt8REQkScygiIhkQImLJBigiIhkQIkBiiU+IiK6r5UrV8LLywu2trYIDAzEsWPHanTexo0boVKp8Pzzz5t9TQYoIiIZEEQ8zJWQkIDIyEjExMQgJSUF7du3R3BwMLKzs6s978qVK5g2bRq6d+9uwVUZoIiIZMGgEu/Q6/UoKCgwOfR6fZXXXrx4McaOHYuwsDD4+fkhLi4O9vb2WLt2bZXnlJeXY/jw4Zg9ezZatWpl0WdmgCIiUhidTgdHR0eTQ6fTVdq3pKQEycnJ0Gq1xja1Wg2tVoukpKQqrzFnzhy4uLhg9OjRFs+TiySIiGRAzEUSUVFRiIyMNGnTaDSV9s3NzUV5eTlcXV1N2l1dXXHu3LlKzzl8+DDWrFmDkydPPtA8GaCIiGRAzJ0kNBpNlQHpQf3xxx8YOXIkVq9eDWdn5wcaiwGKiIiq5OzsDCsrK2RlZZm0Z2Vlwc3NrUL/3377DVeuXMGAAQOMbQbDvfyvQYMGOH/+PLy9vWt0bd6DIiKSAQME0Q5z2NjYICAgAImJiX/NxWBAYmIiunbtWqH/I488gjNnzuDkyZPG47nnnkPv3r1x8uRJeHh41PjazKCIiGSgPh/UjYyMRGhoKDp27IjOnTsjNjYWRUVFCAsLAwCEhITA3d0dOp0Otra2eOyxx0zOb9y4MQBUaL8fBigiIqrW4MGDkZOTg+joaGRmZsLf3x979uwxLpxIT0+HWi1+QU4lCIIkdnG3s/Os7ymQQhRc2VvfUyCFsHb1FW2sOZ7DRRsr+mq8aGPVJmZQREQywL34iIiIJIIZFBGRDCjxhYUMUEREMmDu8vB/Apb4iIhIkphBERHJgPLyJwYoIiJZ4Co+M/zwww8YMWIEunbtiuvXrwMA1q9fj8OHD4s2OSIiUi6LAtSWLVsQHBwMOzs7nDhxwviiq/z8fMyfP1/UCRIRUf3txVefLApQ7733HuLi4rB69WpYW1sb27t164aUlBTRJkdERPfU5yvf64tFAer8+fPo0aNHhXZHR0fcvn37QedERERkWYByc3PDxYsXK7QfPnzY4nfPExFR1QwiHnJhUYAaO3YspkyZgqNHj0KlUuHGjRuIj4/HtGnTEB4eLvYciYgUT4n3oCxaZj5jxgwYDAY89dRTKC4uRo8ePaDRaDBt2jRMmjRJ7DkSEZECPdDrNkpKSnDx4kUUFhbCz88PDg4OFk+Er9ugusLXbVBdEfN1GxFeQ0Qba8mVjaKNVZssyqA2bNiAF198Efb29vDz8xN7TkRE9D/kdO9ILBbdg4qIiICLiwuGDRuG3bt3o7y8XOx5ERGRwlkUoDIyMrBx40aoVCoMGjQIzZs3x4QJE3DkyBGx50dERAAEEf9PLiwKUA0aNED//v0RHx+P7OxsLFmyBFeuXEHv3r3h7e0t9hyJiEiBHnizWHt7ewQHByMvLw9Xr15FamqqGPMiIqK/UeI9KIsDVHFxMbZt24b4+HgkJibCw8MDQ4cOxZdffinm/IiICMp8YaFFAWrIkCHYuXMn7O3tMWjQILzzzjvo2rWr2HMjIiIFsyhAWVlZYdOmTQgODoaVlZXYcyIiov+hvPzJwgAVHx8v9jyIiKgaLPFVY9myZRg3bhxsbW2xbNmyavtOnjz5gSemRK+9FoKIiHFwdW2GM2dSERkZg+PHT1Xat02bhxEdPRUdOjwGT08PvPnmbKxYsdakj4NDQ8TETMVzzwWjWTNnnDr1K6ZNexfJyafr4uOQhP136y58unEbcm/lwde7JWZOGYe2fq2r7L9+09dI+HoPMrJy0NixEZ7pFYQ3xoVAo7EBABw/+Qs+3bgNZ8//hpybt7B03kw81b1LXX0c+oeqcYBasmQJhg8fDltbWyxZsqTKfiqVigHKAi+/3B8LF76NSZNm4eefT2LixFHYvn092rfvjZycmxX629vb4fLldGzdugsLF0ZXOuaqVQvh5+eLUaMikJGRhaFDX8CuXfF4/HEtbtzIqu2PRBL1TeIPeH/lGkRPfR3t/Fpj/ebteG1aDHbEr0JTp8YV+u/adwhLPl6HudMnw/+xR3Dl9xt4W7cUKpUKb00cDQC4c1cPX++WeKGvFm+8ravjT6QMXMVXjcuXL1f6ZxLH5Mlj8OmnG7F+/WYAwKRJM9Gnz5MIDR2EDz9cVaF/cvJpYyY0d+70Cj+3tdXg+ef74JVXxuLHH48BAObNi0XfvlqMHTsSs2d/WIufhqRs3aav8XL/Z/BCXy0AIHrq6/g+6Ti27foOY0a8XKH/yV9S0eGxNuj3dE8AgHtzV/R9qjtOp6YZ+3TvEoDuXQLq5gMolJwesBWLRQ/qzpkzB8XFxRXa79y5gzlz5jzwpJTG2toaHTq0xf79h41tgiBg//7D6Nz5cYvGbNCgARo0aIC7d/Um7Xfv3kVQUMcHmi/JV2lpKc6mXUSXjv7GNrVajS4B7XHq13OVnuP/WBucTfsNZ87eC0i/38jE9z8lMyBRrbMoQM2ePRuFhYUV2ouLizF79uz7nq/X61FQUGByPMCm6rLn7OyEBg0aIDs716Q9OzsXbm7NLBqzsLAIP/2UjKioSWje3AVqtRpDhryAwMDH4ebmIsa0SYby8gtQXm6oUMpr2qQxcm/drvScfk/3xIRRwzBy4gz4934BfYaMQ6cOj2HcyEG1P2Ey4gsLa0gQBKhUqgrtp06dQpMmTe57vk6ng6Ojo8lRVpZvyVSoGqNGvQGVSoVLl35Gfv4FTJjwKjZt2g6DQbm/DJD5jp04g9UbNuPtyPHY9MkSxL4Xhe+TjiPuc3m8suGfQol78Zm1zNzJyQkqlQoqlQqtW7c2CVLl5eUoLCzE+PHj7ztOVFQUIiMjTdpcXB4zZyr/KLm5eSgrK4OLi7NJu4uLMzIzcywe9/LldDzzzGDY29uhUaOHkJmZjfXrV+Dy5fQHnTLJlJNjI1hZqXEz77ZJ+81bt+HcpHGl56xYE48Bz/TGy/2fAQC09vbCnbt3MfuDlRg3chDUaot+zyW6L7MCVGxsLARBwKhRozB79mw4Ojoaf2ZjYwMvL68a7Sih0Wig0WhM2irLyJSitLQUJ06cQe/e3bBjx72X6alUKvTu3Q1xcZ8/8PjFxXdQXHwHjRs3glbbA7NmcZWVUllbW8OvtQ+OJp8yLgM3GAw4mnIaQ1/oV+k5d+/qof6f/31a/X9QUnJpvq7JqTQnFrMCVGhoKACgZcuWCAoKgrW1da1MSomWLfsEq1cvQnLyaRw/fgoTJ46Cvb091q27t6rvk08W48aNTERHvw/g3n9o2rR5GMC9Xw5atHBDu3Z+KCwswqVLVwEAWm0PqFQqpKVdgre3J+bPn4m0tN+MY5IyhQwaiFm6WDzq64PH2rTGhs3bcefOXTzf9ykAQNS8JXBxboKI1+79771nUCes2/Q1HmndCu3atEb69QwsXxOPnkGdjTvJFBffQfr1DOM1rmdk4dyFS3Bs9BCau1p2H5VMGRT4y0CNA1RBQQEaNWoEAOjQoQPu3LmDO3fuVNr3z35Uc19+uRPOzk0RHR0JV9dmOH36LAYODDEunPDwaAGD4a/foZo3d8XRo98Y/x4R8RoiIl7D998nITj43quhHR0fwpw50+Hu7oZbt/Lx9dffICbmA5SVldXthyNJ6fNUd+TdzseKtV8g91YeHvFphbgP34VzEycAQEZWjknG9FrIYKhUKiz/ZAOyc27BqXEj9ArqjMljRxj7/HL+IkZNmWX8+/sr1gAABj77JObNfKNuPhj946iEGuboVlZWyMjIgIvLvRVhlZXk/lw8Yckbdu3sPM0+h8gSBVf21vcUSCGsXX1FG2uE54uijbXh6lbRxqpNNc6g9u/fb1yhd+DAgVqbEBERVcS9+KrRs2fPSv9MRERUGyxaH7pnzx4cPvzXrgcrV66Ev78/hg0bhry8PNEmR0RE9yjxOSiLAtSbb76JgoICAMCZM2cQGRmJvn374vLlyxWebyIiogenxJ0kLHof1OXLl+Hn5wcA2LJlCwYMGID58+cjJSUFffv2FXWCRESkTBZlUDY2NsbNYr/77js888y9J8ybNGlizKyIiEg8BgiiHXJhUQb1xBNPIDIyEt26dcOxY8eQkJAAAEhLS8O//vUvUSdIRER83UaNrVixAg0aNMCXX36JVatWwd3dHQDwzTff4NlnnxV1gkREpEw1flC3tvFBXaorfFCX6oqYD+q+6PmcaGNtvbpdtLFqk0UlPuDe7uVfffUVUlNTAQCPPvoonnvuOePeXEREJB6J5BJ1yqIAdfHiRfTt2xfXr1+Hr++93xB0Oh08PDywa9cueHt7izpJIiJSHovuQU2ePBne3t74/fffkZKSgpSUFKSnp6Nly5aYPHmy2HMkIlI8ruKroUOHDuGnn34yeXtu06ZNsWDBAnTr1k20yRER0T1yesBWLBZlUBqNBn/88UeF9sLCQtjY2DzwpIiIiCwKUP3798e4ceNw9OhRCIIAQRDw008/Yfz48XjuOfFWmhAR0T31vRffypUr4eXlBVtbWwQGBuLYsWNV9t26dSs6duyIxo0bo2HDhvD398f69evNvqZFAWrZsmXw8fFBUFAQbG1tYWtri27dusHHxwdLly61ZEgiIqpGfd6DSkhIQGRkJGJiYpCSkoL27dsjODgY2dnZlfZv0qQJZs2ahaSkJJw+fRphYWEICwvDt99+a9Z1zXoOymAw4IMPPsD27dtRUlKCf//73wgNDYVKpUKbNm3g4+Nj1sX/js9BUV3hc1BUV8R8Dqrvv8Xb53R3+m6z+gcGBqJTp05YsWIFgHuxwMPDA5MmTcKMGTNqNMbjjz+Ofv36Ye7cuTW+rlkZ1Lx58zBz5kw4ODjA3d0du3fvxldffYUBAwY8UHAiIqLq/Xk7RYxDr9ejoKDA5NDr9ZVet6SkBMnJydBqtcY2tVoNrVaLpKSkGs07MTER58+fR48ePcz6zGYFqHXr1uE///kPvv32W3z11VfYsWMH4uPjYTAocX0JEVHdEfN1GzqdDo6OjiaHTqer9Lq5ubkoLy+Hq6urSburqysyMzOrnG9+fj4cHBxgY2ODfv36Yfny5Xj66afN+sxmLTNPT083eZ2GVquFSqXCjRs3uEksEZFMREVFVXh3n0ajEfUaDz30EE6ePInCwkIkJiYiMjISrVq1Qq9evWo8hlkBqqysDLa2tiZt1tbWKC0tNWcYIiIyk5i7mWs0mhoHJGdnZ1hZWSErK8ukPSsrC25ublWep1arjbd+/P39kZqaCp1OV3sBShAEvPrqqyYf7O7duxg/fjwaNmxobNu6das5wxIR0X3U1w4QNjY2CAgIQGJiIp5//vl7czEYkJiYiIkTJ9Z4HIPBUOV9rqqYFaBCQ0MrtI0YMcKsCxIRkbxERkYiNDQUHTt2ROfOnREbG4uioiKEhYUBAEJCQuDu7m68j6XT6dCxY0d4e3tDr9dj9+7dWL9+PVatWmXWdc0KUJ9++qlZgxMRkTjqczfzwYMHIycnB9HR0cjMzIS/vz/27NljXDiRnp4OtfqvNXdFRUV4/fXXce3aNdjZ2eGRRx7Bhg0bMHjwYLOuy/dBkeLwOSiqK2I+B9X7X+atgKvOgWv7RBurNlm0kwQREVFts/iFhUREVHfEXMUnFwxQREQyYJDG3Zg6xRIfERFJEjMoIiIZUF7+xABFRCQLcnpVu1hY4iMiIkliBkVEJANKzKAYoIiIZEAieyrUKZb4iIhIkphBERHJAEt8REQkSUrcSYIlPiIikiRmUEREMqDERRIMUEREMqDEe1As8RERkSQxgyIikgGW+IiISJJY4iMiIpIIZlBERDKgxOegGKCIiGSAb9QlIiKSCGZQREQywBIfERFJEkt8REREEsEMiohIBljiIyIiSWKJj4iISCKYQRERyQBLfEREJEks8REREUkEMygiIhlgiY+IiCRJEAz1PYU6xxIfERFJEjMoIiIZUOILCxmgiIhkQImvfGeJj4iIJIkZFBGRDLDER0REksQSHxERkUQwgyIikgElbnXEAEVEJANK3EmCJT4iIpIkZlBERDKgxEUSDFBERDKgxGXmLPEREZEkMYMiIpIBlviIiEiSlLjMnCU+IiKSJGZQREQyoMQSHzMoIiIZMEAQ7bDEypUr4eXlBVtbWwQGBuLYsWNV9l29ejW6d+8OJycnODk5QavVVtu/KgxQRERUrYSEBERGRiImJgYpKSlo3749goODkZ2dXWn/gwcPYujQoThw4ACSkpLg4eGBZ555BtevXzfruipBInmjnZ1nfU+BFKLgyt76ngIphLWrr2hjNWrYSrSxcm6lQq/Xm7RpNBpoNJpK+wcGBqJTp05YsWIFAMBgMMDDwwOTJk3CjBkz7nu98vJyODk5YcWKFQgJCanxPJlBERHJgEEQRDt0Oh0cHR1NDp1OV+l1S0pKkJycDK1Wa2xTq9XQarVISkqq0dyLi4tRWlqKJk2amPWZuUiCiEhhoqKiEBkZadJWVfaUm5uL8vJyuLq6mrS7urri3LlzNbre9OnT0aJFC5MgVxMMUEREMiDmbubVlfPEtmDBAmzcuBEHDx6Era2tWecyQBERyUB9Pajr7OwMKysrZGVlmbRnZWXBzc2t2nM//PBDLFiwAN999x3atWtn9rV5D4qIiKpkY2ODgIAAJCYmGtsMBgMSExPRtWvXKs97//33MXfuXOzZswcdO3a06NrMoIiIZKA+F1xHRkYiNDQUHTt2ROfOnREbG4uioiKEhYUBAEJCQuDu7m5caLFw4UJER0fjiy++gJeXFzIzMwEADg4OcHBwqPF1GaCIiGSgPt+oO3jwYOTk5CA6OhqZmZnw9/fHnj17jAsn0tPToVb/VZBbtWoVSkpK8PLLL5uMExMTg3fffbfG1+VzUKQ4fA6K6oqYz0FpbD1EG0t/93fRxqpNzKCIiGRAIrlEnWKAIiKSASUGKK7iIyIiSWIGRUQkA8rLnyS0SILMo9frodPpEBUVVWdPhJMy8btG9YUBSqYKCgrg6OiI/Px8NGrUqL6nQ/9g/K5RfeE9KCIikiQGKCIikiQGKCIikiQGKJnSaDSIiYnhTWuqdfyuUX3hIgkiIpIkZlBERCRJDFBERCRJDFBERCRJDFBERCRJDFAK4eXlhdjY2PqeBsnIwYMHoVKpcPv27Wr78btFtYUBSgSvvvoqVCoVFixYYNL+1VdfQaVS1elcPvvsMzRu3LhC+88//4xx48bV6Vyobvz5/VOpVLCxsYGPjw/mzJmDsrKyBxo3KCgIGRkZcHR0BMDvFtU9BiiR2NraYuHChcjLy6vvqVSqWbNmsLe3r+9pUC159tlnkZGRgQsXLmDq1Kl499138cEHHzzQmDY2NnBzc7vvL1n8blFtYYASiVarhZubG3Q6XZV9Dh8+jO7du8POzg4eHh6YPHkyioqKjD/PyMhAv379YGdnh5YtW+KLL76oUD5ZvHgx2rZti4YNG8LDwwOvv/46CgsLAdwryYSFhSE/P9/4G/W7774LwLQMM2zYMAwePNhkbqWlpXB2dsa6desAAAaDATqdDi1btoSdnR3at2+PL7/8UoR/KaoNGo0Gbm5u8PT0RHh4OLRaLbZv3468vDyEhITAyckJ9vb26NOnDy5cuGA87+rVqxgwYACcnJzQsGFDPProo9i9ezcA0xIfv1tUHxigRGJlZYX58+dj+fLluHbtWoWf//bbb3j22Wfx0ksv4fTp00hISMDhw4cxceJEY5+QkBDcuHEDBw8exJYtW/Dxxx8jOzvbZBy1Wo1ly5bh119/xeeff479+/fjrbfeAnCvJBMbG4tGjRohIyMDGRkZmDZtWoW5DB8+HDt27DAGNgD49ttvUVxcjBdeeAEAoNPpsG7dOsTFxeHXX39FREQERowYgUOHDony70W1y87ODiUlJXj11Vdx/PhxbN++HUlJSRAEAX379kVpaSkAYMKECdDr9fj+++9x5swZLFy4EA4ODhXG43eL6oVADyw0NFQYOHCgIAiC0KVLF2HUqFGCIAjCtm3bhD//iUePHi2MGzfO5LwffvhBUKvVwp07d4TU1FQBgPDzzz8bf37hwgUBgLBkyZIqr71582ahadOmxr9/+umngqOjY4V+np6exnFKS0sFZ2dnYd26dcafDx06VBg8eLAgCIJw9+5dwd7eXjhy5IjJGKNHjxaGDh1a/T8G1bm/f/8MBoOwb98+QaPRCM8//7wAQPjxxx+NfXNzcwU7Ozth06ZNgiAIQtu2bYV333230nEPHDggABDy8vIEQeB3i+oe36grsoULF+LJJ5+s8NvlqVOncPr0acTHxxvbBEGAwWDA5cuXkZaWhgYNGuDxxx83/tzHxwdOTk4m43z33XfQ6XQ4d+4cCgoKUFZWhrt376K4uLjG9wEaNGiAQYMGIT4+HiNHjkRRURG+/vprbNy4EQBw8eJFFBcX4+mnnzY5r6SkBB06dDDr34Pqxs6dO+Hg4IDS0lIYDAYMGzYML774Inbu3InAwEBjv6ZNm8LX1xepqakAgMmTJyM8PBx79+6FVqvFSy+9hHbt2lk8D363SEwMUCLr0aMHgoODERUVhVdffdXYXlhYiNdeew2TJ0+ucM6///1vpKWl3XfsK1euoH///ggPD8e8efPQpEkTHD58GKNHj0ZJSYlZN6qHDx+Onj17Ijs7G/v27YOdnR2effZZ41wBYNeuXXB3dzc5jxuGSlPv3r2xatUq2NjYoEWLFmjQoAG2b99+3/PGjBmD4OBg7Nq1C3v37oVOp8OiRYswadIki+fC7xaJhQGqFixYsAD+/v7w9fU1tj3++OM4e/YsfHx8Kj3H19cXZWVlOHHiBAICAgDc+23z76sCk5OTYTAYsGjRIqjV924fbtq0yWQcGxsblJeX33eOQUFB8PDwQEJCAr755hu88sorsLa2BgD4+flBo9EgPT0dPXv2NO/DU71o2LBhhe9WmzZtUFZWhqNHjyIoKAgAcPPmTZw/fx5+fn7Gfh4eHhg/fjzGjx+PqKgorF69utIAxe8W1TUGqFrQtm1bDB8+HMuWLTO2TZ8+HV26dMHEiRMxZswYNGzYEGfPnsW+ffuwYsUKPPLII9BqtRg3bhxWrVoFa2trTJ06FXZ2dsZlvj4+PigtLcXy5csxYMAA/Pjjj4iLizO5tpeXFwoLC5GYmIj27dvD3t6+ysxq2LBhiIuLQ1paGg4cOGBsf+ihhzBt2jRERETAYDDgiSeeQH5+Pn788Uc0atQIoaGhtfCvRmJ7+OGHMXDgQIwdOxYfffQRHnroIcyYMQPu7u4YOHAgAOCNN95Anz590Lp1a+Tl5eHAgQNo06ZNpePxu0V1rr5vgv0T/P0m9Z8uX74s2NjYCH//Jz527Jjw9NNPCw4ODkLDhg2Fdu3aCfPmzTP+/MaNG0KfPn0EjUYjeHp6Cl988YXg4uIixMXFGfssXrxYaN68uWBnZycEBwcL69atM7mRLQiCMH78eKFp06YCACEmJkYQBNMb2X86e/asAEDw9PQUDAaDyc8MBoMQGxsr+Pr6CtbW1kKzZs2E4OBg4dChQw/2j0Wiq+z796dbt24JI0eOFBwdHY3fmbS0NOPPJ06cKHh7ewsajUZo1qyZMHLkSCE3N1cQhIqLJASB3y2qW3wflIRdu3YNHh4e+O677/DUU0/V93SIiOoUA5SE7N+/H4WFhWjbti0yMjLw1ltv4fr160hLSzPW8ImIlIL3oCSktLQUM2fOxKVLl/DQQw8hKCgI8fHxDE5EpEjMoIiISJK41REREUkSAxQREUkSAxQREUkSAxQREUkSAxQREUkSAxQREUkSAxQREUkSAxQREUnS/wEwsF82CYC1OAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizing-placing values between 0-1\n",
    "conf_matrix = conf_matrix.astype(\"float\") / conf_matrix.sum(axis=1)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(conf_matrix,annot=True,annot_kws={\"size\":10} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [\"Negative\",\"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"this was the wost experiecen of my life, want my time back\"])\n",
    "test = pad_sequences(sequence,maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test),decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"one of the best weddings i've ever attended\"])\n",
    "test = pad_sequences(sequence,maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test),decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"im not thinking about anything right now\"])\n",
    "test = pad_sequences(sequence,maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test),decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"our team lost, we need to prepare better for the next matches\"])\n",
    "test = pad_sequences(sequence,maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test),decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"our team gain experience by winning\"])\n",
    "test = pad_sequences(sequence,maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test),decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"enjoying my life\"])\n",
    "test = pad_sequences(sequence,maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test),decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Model for AWS SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving weights and tokenizer so we can reduce training time on SageMaker\n",
    "\n",
    "#serialize model to JSON\n",
    "model_json = best_model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#serialize weights to HDF5\n",
    "best_model.save_weights(\"model-weights.h5\")\n",
    "print(\"Model saved\")\n",
    "\n",
    "#saving tokenizer\n",
    "with open(\"tokenizer.pickle\",\"wb\") as handle :\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Tokenizer saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
